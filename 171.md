以下是三種方案的比較整理，涵蓋 **時間複雜度、效能、中文支援、索引大小、維護成本、適用場景**：

***

### ✅ **1. PostgreSQL 無索引 (`LIKE '%pattern%'`)**

*   **時間複雜度**：  
    $$O(N \cdot L)$$  
    N = 資料列數，L = 平均字串長度。必須全表掃描。
*   **效能**：  
    百萬筆資料 → 秒級甚至分鐘級，非常慢。
*   **中文支援**：  
    無特別優化，純字元比對。
*   **索引大小**：  
    無索引，無額外空間。
*   **維護成本**：  
    無。
*   **適用場景**：  
    資料量小、一次性查詢。

***

### ✅ **2. PostgreSQL `pg_trgm` + GIN**

*   **時間複雜度**：  
    $$O(T \cdot \log M + k \cdot L)$$  
    T = pattern trigram 數量，M = 索引大小，k = 候選筆數（通常 ≪ N）。
*   **效能**：  
    百萬筆資料 → 毫秒到數百毫秒（取決於候選數量）。
*   **中文支援**：  
    **弱**，因為中文無空白分詞，短 pattern（1–2 字）無法產生 trigram → 索引無法過濾。
*   **索引大小**：  
    約原始資料大小的 2–3 倍。
*   **維護成本**：  
    插入/更新成本高（GIN 索引維護）。
*   **適用場景**：  
    英文或長字串模糊搜尋；中文長詞可用，短詞不佳。

***

### ✅ **3. Elasticsearch（倒排索引）**

*   **時間複雜度**：  
    $$O(T \cdot \log M + K)$$  
    T = token 數量，M = 索引大小，K = 候選文件數。
*   **效能**：  
    百萬筆資料 → 毫秒級（posting list 合併非常快）。
*   **中文支援**：  
    **強**，可用中文分詞器（IK、jieba）；短詞查詢也可處理。
*   **索引大小**：  
    約原始資料大小的 2–5 倍（依分詞策略）。
*   **維護成本**：  
    需要獨立服務、集群管理、分詞器配置。
*   **適用場景**：  
    大規模全文檢索、複雜查詢（排序、權重、模糊、拼音）、高併發。

***

#### **總結建議**

*   **資料量小、偶爾查詢** → PostgreSQL 無索引即可。
*   **資料量中等、主要英文或長詞模糊搜尋** → `pg_trgm + GIN`。
*   **中文短詞、搜尋頻繁、需要高效能與擴展性** → Elasticsearch。

***

要不要我幫你 **畫一個表格 + 圖表**（三種方案的效能 vs 資料量）並給出 **中文搜尋最佳策略**（pg\_bigm vs Elasticsearch vs zhparser）？
