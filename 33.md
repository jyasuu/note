Here's a step-by-step guide to set up a CDC demo using PostgreSQL, Debezium, and Kafka:

### 1. Prerequisites
- Docker and Docker-compose installed
- Basic understanding of Kafka concepts
- curl, jq (for testing)

### 2. Setup Infrastructure with Docker

Create `docker-compose.yml`:
```yaml
version: '3.7'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092

  postgres:
    image: debezium/postgres:13
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - ./postgres-init.sql:/docker-entrypoint-initdb.d/postgres-init.sql

  connect:
    image: debezium/connect:1.9
    ports:
      - "8083:8083"
    depends_on:
      - kafka
      - postgres
    environment:
      - BOOTSTRAP_SERVERS=kafka:9092
      - GROUP_ID=1
      - CONFIG_STORAGE_TOPIC=my_connect_configs
      - OFFSET_STORAGE_TOPIC=my_connect_offsets
      - STATUS_STORAGE_TOPIC=my_connect_statuses
```

### 3. Configure PostgreSQL for CDC
Create `postgres-init.sql`:
```sql
ALTER SYSTEM SET wal_level = logical;
CREATE USER debezium WITH REPLICATION LOGIN PASSWORD 'dbz';
CREATE DATABASE inventory;
GRANT ALL PRIVILEGES ON DATABASE inventory TO debezium;
```

### 4. Start Services
```bash
docker-compose up -d
```

### 5. Create Debezium Connector
```bash
curl -i -X POST -H "Accept:application/json" \
  -H "Content-Type:application/json" \
  localhost:8083/connectors/ \
  -d '{
    "name": "inventory-connector",
    "config": {
      "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
      "database.hostname": "postgres",
      "database.port": "5432",
      "database.user": "debezium",
      "database.password": "dbz",
      "database.dbname": "inventory",
      "database.server.name": "dbserver1",
      "table.include.list": "public.*",
      "plugin.name": "pgoutput"
    }
  }'
```

### 6. Test the Setup

**Create test table and data:**
```bash
docker-compose exec postgres psql -U postgres -d inventory

-- In PSQL console:
CREATE TABLE customers (
  id SERIAL PRIMARY KEY,
  name VARCHAR(255) NOT NULL,
  email VARCHAR(255) NOT NULL
);

INSERT INTO customers (name, email) VALUES
('John Doe', 'john@example.com'),
('Jane Smith', 'jane@example.com');
```

**Check Kafka topics:**
```bash
docker-compose exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

**Consume messages from Kafka:**
```bash
docker-compose exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic dbserver1.public.customers \
  --from-beginning
```

### 7. Test CDC Operations

Make changes in PostgreSQL and watch Kafka messages:
```sql
UPDATE customers SET email='john.doe@example.com' WHERE id=1;
DELETE FROM customers WHERE id=2;
```

### 8. Clean Up
```bash
docker-compose down -v
```

### Key Components Explained:
1. **PostgreSQL**: Source database configured for logical replication
2. **Debezium**: Captures changes from PostgreSQL WAL (Write-Ahead Log)
3. **Kafka Connect**: Manages connectors and streams data to Kafka topics
4. **Kafka**: Distributed event streaming platform
5. **Zookeeper**: Coordination service for Kafka

### Troubleshooting Tips:
1. Check connector status:
   ```bash
   curl -s localhost:8083/connectors/inventory-connector/status | jq
   ```
2. View connector logs:
   ```bash
   docker-compose logs connect
   ```
3. Verify PostgreSQL replication settings:
   ```bash
   docker-compose exec postgres cat /var/lib/postgresql/data/postgresql.conf | grep wal_level
   ```

This POC demonstrates:
- Real-time data capture from PostgreSQL
- Change event streaming to Kafka
- Support for insert/update/delete operations
- Schema evolution tracking

For production use, you'd want to add:
- Security (SSL, authentication)
- Monitoring
- Error handling
- Schema registry
- Proper retention policies
- Horizontal scaling
