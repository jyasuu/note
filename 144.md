https://github.com/Amineharrabi/MNIST_In_Rust


這段文字是來自一個 **YouTube 影片的逐字稿**，該影片內容是關於 **如何使用 Rust 程式語言從零開始建構一個神經網路**。它詳細解釋了 **神經網路的核心數學原理**，包括如何計算加權和、應用 **ReLU 等非線性啟用函數**，以及如何使用 **Softmax 將輸出轉換為機率**。影片深入探討了 **訓練過程**，特別是利用 **反向傳播 (Backpropagation)** 和 **梯度下降 (Gradient Descent)** 來調整權重以最小化 **交叉熵損失 (Cross-Categorical Entropy Loss)**。最後，它概述了 **Rust 程式碼的結構**，包括初始化網路參數、處理 MNIST 資料集，以及協調訓練和評估的 **主函式**。


這是一個非常深入的課題。根據您的來源，要從頭開始使用 Rust 構建神經網路，您需要完全依賴純粹的 Rust 程式碼和原始數學運算，不使用 TensorFlow、PyTorch 或任何現成的機器學習函式庫。最終的目標是建立一個能夠理解手寫內容的機器。

以下是從結構初始化到訓練更新的詳細步驟：

### 1. 核心結構與數學基礎

#### 神經元與層次 (The Neuron and Layers)
*   單個神經元的作用是接收輸入，將每個輸入乘以一個權重（weight），加上一個偏差（bias），然後輸出結果；這本質上是一個加權總和。
*   為了使網路夠強大，需要多層和多個連接，每個神經元的輸出成為下一層的輸入。

#### 線性代數的應用 (Linear Algebra)
*   大量的單獨乘法計算可以透過線性代數來解決。所有這些單獨的乘法運算都會變成一個矩陣操作：**點積**（dot product）。
*   在 Rust 中實現時，您必須處理 Rust 的借用檢查器（borrow checker），但一旦克服，程式碼會相對簡潔。

### 2. 初始化網路參數

網路的核心結構由矩陣和向量組成，需要手動初始化：

*   **權重矩陣 ($W$):** 需要兩個矩陣來儲存權重：
    *   $W_1$：連接輸入層與隱藏層。
    *   $W_2$：連接隱藏層與輸出層。
    *   **初始化：** 權重 $W$ 應初始化為**隨機值**，這是為了確保神經元不會學習到完全相同特徵，並在訓練期間擁有獨特的梯度路徑。
*   **偏差向量 ($B$):** 需要兩個偏差向量：
    *   $B_1$：用於隱藏層。
    *   $B_2$：用於輸出層。
    *   **初始化：** 偏差向量 $B$ 可以初始化為**零**，因為它們在訓練期間可以自由調整。
*   **網路實例化：** 初始化網路實例時，需要指定層次大小。例如，輸入層大小為 748，隱藏層大小為 46，輸出層大小為 10。

### 3. 前向傳播 (Forward Pass)

資料流經網路的順序是：輸入 $\rightarrow$ 線性轉換 $\rightarrow$ 啟動函式 $\rightarrow$ 線性轉換 $\rightarrow$ 輸出。

#### 核心計算步驟：
1.  **隱藏層預啟動值 ($Z_1$):**
    *   矩陣乘法 $W_1 \cdot X$ 將學習權重應用於輸入向量 $X$。
    *   加上偏差向量 $B_1$ 會獨立地移動每個神經元的啟動閾值。
    *   $Z_1 = W_1 \cdot X + B_1$ 計算出隱藏層的預啟動值。
2.  **非線性啟動函式 (Activation Function):**
    *   如果僅堆疊線性層，網路行為仍然是線性的。
    *   為了讓網路強大，需要引入非線性。可以使用 **ReLU (Rectified Linear Unit)**，其規則很簡單：如果輸入是正數，則傳遞；如果是負數，則輸出零。
3.  **輸出層預啟動值 ($Z_2$):**
    *   $A_1$ 為經過 $Z_1$ 啟動後的數值。
    *   $Z_2 = W_2 \cdot A_1 + B_2$。
4.  **輸出轉換 (Softmax):**
    *   最後，加入 **Softmax** 函式，將網路輸出轉換為機率（數值總和為一），這適用於判斷網路對結果的信心程度。

### 4. 訓練機制

#### 衡量錯誤 (Loss Function)
*   需要量化網路的錯誤程度。**交叉類別熵損失**（Cross Categorical Entropy Loss）用於此目的，當預測結果越好，該數值會越小。

#### 調整參數 (Backpropagation and Gradient Descent)
*   **反向傳播 (Backpropagation):** 這是找出錯誤歸咎於哪個權重及其程度的過程。
    *   它追蹤誤差，向後穿過網路，計算每個權重對最終錯誤的貢獻程度。
    *   `backward` 方法手動實現微積分的**連鎖律**（chain rule of calculus），計算損失函式對於所有參數的梯度。這包括計算損失對於輸出預啟動值 ($Z_2$) 的梯度，然後對於 $W_2$ 矩陣的梯度，接著是隱藏層和隱藏層預啟動的梯度。
*   **梯度下降更新 (Gradient Descent):**
    *   `update` 方法用於更新網路參數，更新方向與梯度方向相反。
    *   更新公式為：**參數 = 參數 -（學習率 $\times$ 梯度）**。
    *   **學習率 (Learning Rate, LR)** 用於調整步長。學習率太大會導致發散（divergence），太小會阻礙學習速度。

### 5. 實作與流程管理

*   **資料處理：** 載入資料（例如 MNIST CSV 檔案），解析標籤，並將圖像的灰階值進行**正規化**。
*   **工具函式：** 編寫實用函式，例如**準確度函式**（accuracy function）。
*   **主流程：** 主函式（main function）負責協調整個訓練和評估流程。
    *   載入訓練和測試資料集。
    *   定義超參數（hyperparameters），例如**訓練週期數**（number of epoches）、學習率和**批量大小**（batch size）。
    *   訓練會持續固定的週期數，並追蹤損失和準確度。
*   **錯誤處理：** 所有的操作都應包裹在 **Result 類型**中，以便傳播任何可能發生的錯誤。

神經網路利用線性代數和特定的數學函數來處理手寫數字的過程，是建立在純粹的原始數學運算之上，即便在沒有現成的機器學習函式庫（如 TensorFlow 或 PyTorch）的情況下，也能實現複雜的學習行為。

這個過程主要分為兩個階段：**前向傳播（使用線性代數與激活函數進行轉換）**和**訓練（使用特定的損失函數和微積分進行更新）**。

---

### 1. 線性代數：核心轉換與效率

線性代數是神經網路執行數據轉換和實現計算效率的基礎。

#### 神經元和加權和 (Weighted Sums)
*   單個神經元會接收輸入，將每個輸入乘以一個**權重**，然後將結果與**偏差**（bias）相加，最後吐出一個結果。這個過程就是一個**加權和**（weighted sum）。
*   學習的發生在於調整這些權重，以獲得更好的輸出。

#### 矩陣運算 (Matrix Operations)
*   由於神經網路涉及大量的層次和連接，會有許多單獨的計算。
*   **線性代數**將這些大量的個別乘法運算整合為**一個矩陣運算**，從而節省了計算資源。
*   **點積**（dot product）作為矩陣操作的一種，可以在單一操作中處理所有計算。

#### 前向傳播中的線性轉換
*   在網路結構中，我們使用兩個矩陣來儲存權重（一個連接輸入層與隱藏層，另一個連接隱藏層與輸出層），以及兩個偏差向量（分別用於隱藏層和輸出層）。
*   在運算中，**矩陣乘法**（例如 `W1.x`）將學習到的權重應用於輸入向量。
*   **線性轉換**是應用非線性激活函數之前的第一步。這個轉換計算隱藏層的預激活值。
*   接著，加入**偏差向量**（B1）會獨立地移動每個神經元的激活閾值（activation threshold）。

---

### 2. 特定的數學函數：非線性與概率輸出

單純堆疊線性層（linear layers）只會產生線性行為，這並不有趣。因此，神經網路需要特定的非線性函數來實現複雜的學習能力。

#### 整流線性單元（Rectified Linear Unit, ReLU）
*   ReLU 引入了**微小的非線性**，這是使神經網路真正強大的關鍵。
*   **功能**：如果輸入是正數，則直接通過；如果是負數，則輸出零。

#### Softmax 函數（Softmax Function）
*   Softmax 函數的目的是將網路輸出轉換成**概率**。
*   **功能**：它將任何一組數字轉換為總和為一的值，這非常適合表達網路的自信程度，例如判斷是貓還是狗的信心。

---

### 3. 訓練階段：損失函數與微積分

訓練網路需要衡量預測的錯誤程度，並計算如何調整權重。

#### 測量錯誤：交叉類別熵損失 (Cross Categorical Entropy Loss)
*   為了訓練網路，我們需要測量「我們錯了多少」。
*   **交叉類別熵損失**（Cross categorial entropy loss）就是用來執行此測量的，它提供了一個數值，當預測變得更好時，該數值會變小。

#### 歸咎權重：反向傳播 (Backpropagation)
*   **反向傳播**（Back propagation）機制會追溯錯誤，從網路輸出端向後追溯，計算每個權重對最終錯誤的貢獻程度。
*   這就好比調整蛋糕配方，確定是糖太多、麵粉不夠，還是香草太多所導致的口感不佳。

#### 權重更新：梯度下降與微積分 (Gradient Descent and Calculus)
*   **後向方法**（backward method）透過手動實現**微積分的鏈式法則**（chain rule of calculus），來計算損失函數相對於所有參數的梯度。
*   計算梯度時，是對輸出預激活值（Z2）以及第二個加權矩陣（W2）進行運算，然後再對隱藏層和隱藏層的預激活值進行相同的運算。
*   **更新方法**（update method）使用**梯度下降**（gradient descent）來更新網路參數，更新的方向與梯度方向相反。
*   **更新公式**：參數會依據 `參數 = 參數 - 學習率 * 梯度` 來更新。
*   **學習率（Learning Rate, LR）**：它用於調整步長（step size）；步長太大會導致發散，太小則會阻礙學習速度。


初始化神經網路的權重（weights）和偏差（biases）是構建網路結構的第一步，並且對於確保訓練過程有效至關重要。

### 1. 核心結構組成

在初始化網路實例時，首先要定義其核心結構，它由兩部分組成：

*   **權重（Weights）：** 需要使用兩個**矩陣**來儲存權重。
    *   一個矩陣 ($W_1$) 連接**輸入層**與**隱藏層**。
    *   另一個矩陣 ($W_2$) 連接**隱藏層**與**輸出層**。
*   **偏差（Biases）：** 需要使用兩個**向量**來儲存偏差。
    *   一個偏差向量 ($B_1$) 用於**隱藏層**。
    *   另一個偏差向量 ($B_2$) 用於**輸出層**。

### 2. 初始化方法與原因

#### 權重（Weights）的初始化
權重應使用**隨機值**進行初始化。

這樣做的目的是：
1.  確保神經元不會學習到**相同的特徵**。
2.  使神經元在訓練期間擁有**獨特的梯度路徑**。

#### 偏差向量（Bias Vectors）的初始化
偏差向量則被初始化為**零**。

這樣做的原因是：
*   偏差向量可以在訓練期間**自由調整**。

一旦網路結構初始化完畢，訓練流程便會定義超參數（如輸入層大小 748、隱藏層大小 46、輸出層大小 10 等），並開始後續的前向傳播和梯度下降等步驟。

## 🧠 神經網路就像一個「數字加工廠」

想像神經網路是一個工廠：
- **輸入** = 原材料（手寫數字的像素）
- **權重** = 加工配方（每個步驟的重要性）
- **輸出** = 成品（識別結果：這是數字 0-9）

## 1. 🏗️ 建立神經網路結構

```rust
// 定義神經網路結構
struct NeuralNetwork {
    w1: Vec<Vec<f64>>, // 輸入層到隱藏層的權重
    b1: Vec<f64>,      // 隱藏層的偏差
    w2: Vec<Vec<f64>>, // 隱藏層到輸出層的權重  
    b2: Vec<f64>,      // 輸出層的偏差
}

impl NeuralNetwork {
    fn new(input_size: usize, hidden_size: usize, output_size: usize) -> Self {
        let mut rng = rand::thread_rng();
        
        // 初始化權重為隨機小數（就像隨機配方）
        let w1 = (0..hidden_size)
            .map(|_| (0..input_size).map(|_| rng.gen::<f64>() * 0.1).collect())
            .collect();
            
        let w2 = (0..output_size)
            .map(|_| (0..hidden_size).map(|_| rng.gen::<f64>() * 0.1).collect())
            .collect();
            
        // 初始化偏差為 0（從零開始調整）
        let b1 = vec![0.0; hidden_size];
        let b2 = vec![0.0; output_size];
        
        NeuralNetwork { w1, b1, w2, b2 }
    }
}
```

**為什麼這樣初始化？**
- **權重隨機**：避免所有神經元學到一樣的東西
- **偏差為零**：從中立位置開始學習

## 2. ➡️ 前向傳播：數據流動過程

```rust
impl NeuralNetwork {
    fn forward(&self, x: &[f64]) -> (Vec<f64>, Vec<f64>, Vec<f64>, Vec<f64>) {
        // 第一層：線性轉換（加權求和）
        let z1 = self.linear_transform(&self.w1, &self.b1, x);
        
        // 激活函數：引入非線性（讓網路更聰明）
        let a1 = self.relu(&z1);
        
        // 第二層：線性轉換
        let z2 = self.linear_transform(&self.w2, &self.b2, &a1);
        
        // Softmax：轉換為機率
        let a2 = self.softmax(&z2);
        
        (z1, a1, z2, a2)
    }
    
    fn linear_transform(&self, w: &[Vec<f64>], b: &[f64], x: &[f64]) -> Vec<f64> {
        w.iter()
            .zip(b)
            .map(|(wi, &bi)| {
                wi.iter()
                    .zip(x)
                    .fold(0.0, |acc, (&w_ij, &x_j)| acc + w_ij * x_j)
                    + bi
            })
            .collect()
    }
    
    fn relu(&self, z: &[f64]) -> Vec<f64> {
        z.iter().map(|&zi| if zi > 0.0 { zi } else { 0.0 }).collect()
    }
    
    fn softmax(&self, z: &[f64]) -> Vec<f64> {
        let max_z = z.iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
        let exp_z: Vec<f64> = z.iter().map(|&zi| (zi - max_z).exp()).collect();
        let sum_exp_z: f64 = exp_z.iter().sum();
        exp_z.iter().map(|&exp_zi| exp_zi / sum_exp_z).collect()
    }
}
```

### 🎯 激活函數比喻

**ReLU** 就像一個「過濾器」：
```
輸入: [-2, 0.5, -1, 3]
ReLU: [0, 0.5, 0, 3]  # 負數變0，正數保留
```

**Softmax** 就像「投票轉機率」：
```
原始分數: [2.0, 1.0, 0.1]
Softmax: [0.65, 0.24, 0.11]  # 加起來 = 1.0
```

## 3. 📉 損失函數：衡量「錯多少」

```rust
impl NeuralNetwork {
    fn cross_entropy_loss(&self, y_pred: &[f64], y_true: &[f64]) -> f64 {
        -y_true
            .iter()
            .zip(y_pred)
            .fold(0.0, |acc, (&y_t, &y_p)| acc + y_t * y_p.ln())
    }
}
```

**交叉熵損失的直觀理解**：
- 如果預測正確（信心 0.9），損失很小：`-ln(0.9) ≈ 0.1`
- 如果預測錯誤（信心 0.1），損失很大：`-ln(0.1) ≈ 2.3`

## 4. 🔙 反向傳播：找出「誰的錯」

這是神經網路最神奇的部分！就像偵探破案：

```rust
impl NeuralNetwork {
    fn backward(
        &self,
        x: &[f64],
        y: &[f64],
        z1: &[f64],
        a1: &[f64],
        z2: &[f64],
        a2: &[f64],
    ) -> (Vec<Vec<f64>>, Vec<f64>, Vec<Vec<f64>>, Vec<f64>) {
        let batch_size = 1; // 這裡簡化為單個樣本
        
        // 1. 計算輸出層誤差：預測 - 真實
        let dz2: Vec<f64> = a2
            .iter()
            .zip(y)
            .map(|(&a2_i, &y_i)| a2_i - y_i)
            .collect();
        
        // 2. 計算權重和偏差的梯度
        let mut dw2 = vec![vec![0.0; self.w2[0].len()]; self.w2.len()];
        let mut db2 = vec![0.0; self.b2.len()];
        
        for i in 0..self.w2.len() {
            for j in 0..self.w2[0].len() {
                dw2[i][j] = dz2[i] * a1[j];
            }
            db2[i] = dz2[i];
        }
        
        // 3. 反向傳播到隱藏層（鏈式法則）
        let mut dz1 = vec![0.0; z1.len()];
        for j in 0..dz1.len() {
            for i in 0..dz2.len() {
                dz1[j] += self.w2[i][j] * dz2[i];
            }
            // ReLU 導數：大於0為1，否則為0
            dz1[j] *= if z1[j] > 0.0 { 1.0 } else { 0.0 };
        }
        
        // 4. 計算第一層梯度
        let mut dw1 = vec![vec![0.0; self.w1[0].len()]; self.w1.len()];
        let mut db1 = vec![0.0; self.b1.len()];
        
        for i in 0..self.w1.len() {
            for j in 0..self.w1[0].len() {
                dw1[i][j] = dz1[i] * x[j];
            }
            db1[i] = dz1[i];
        }
        
        (dw1, db1, dw2, db2)
    }
}
```

### 🔗 鏈式法則的比喻

就像多米諾骨牌：
```
誤差 → 輸出層權重 → 隱藏層輸出 → 隱藏層權重 → 輸入
    dL/dW2        dL/dA1        dL/dW1
```

## 5. 📚 訓練循環：不斷學習

```rust
impl NeuralNetwork {
    fn train(&mut self, x_train: &[Vec<f64>], y_train: &[Vec<f64>], epochs: usize, learning_rate: f64) {
        for epoch in 0..epochs {
            let mut total_loss = 0.0;
            
            for (x, y) in x_train.iter().zip(y_train) {
                // 前向傳播
                let (z1, a1, z2, a2) = self.forward(x);
                
                // 計算損失
                let loss = self.cross_entropy_loss(&a2, y);
                total_loss += loss;
                
                // 反向傳播
                let (dw1, db1, dw2, db2) = self.backward(x, y, &z1, &a1, &z2, &a2);
                
                // 更新參數
                self.update(&dw1, &db1, &dw2, &db2, learning_rate);
            }
            
            println!("Epoch {}: loss = {}", epoch, total_loss / x_train.len() as f64);
        }
    }
    
    fn update(
        &mut self,
        dw1: &[Vec<f64>],
        db1: &[f64],
        dw2: &[Vec<f64>],
        db2: &[f64],
        learning_rate: f64,
    ) {
        // 權重 = 權重 - 學習率 × 梯度
        for i in 0..self.w1.len() {
            for j in 0..self.w1[0].len() {
                self.w1[i][j] -= learning_rate * dw1[i][j];
            }
        }
        
        for i in 0..self.b1.len() {
            self.b1[i] -= learning_rate * db1[i];
        }
        
        for i in 0..self.w2.len() {
            for j in 0..self.w2[0].len() {
                self.w2[i][j] -= learning_rate * dw2[i][j];
            }
        }
        
        for i in 0..self.b2.len() {
            self.b2[i] -= learning_rate * db2[i];
        }
    }
}
```

## 🎯 學習率的重要性

**學習率太小**：學習太慢
```
權重更新：w = w - 0.001 × 梯度  # 像小碎步
```

**學習率太大**：無法收斂  
```
權重更新：w = w - 1.0 × 梯度    # 像亂跳，可能錯過最佳點
```

## 🏆 完整訓練流程

```rust
fn main() {
    // 1. 準備數據（MNIST 手寫數字）
    let (x_train, y_train) = load_mnist_data();
    let (x_test, y_test) = load_test_data();
    
    // 2. 建立神經網路
    let mut nn = NeuralNetwork::new(784, 128, 10); // 784像素 → 128隱藏神經元 → 10個數字
    
    // 3. 訓練
    nn.train(&x_train, &y_train, 100, 0.01); // 100輪，學習率0.01
    
    // 4. 測試
    let accuracy = evaluate(&nn, &x_test, &y_test);
    println!("測試準確率: {:.2}%", accuracy * 100.0);
}
```

## 💡 關鍵概念總結

1. **前向傳播**：數據從輸入流向輸出，進行預測
2. **損失計算**：量化預測與真實值的差距  
3. **反向傳播**：誤差從輸出反向傳播，計算每個參數的責任
4. **梯度下降**：沿著梯度反方向更新參數，減少損失

這個過程就像：
```
看答案 → 發現錯誤 → 找出誰的錯 → 調整配方 → 再次嘗試
```

希望這個通俗的解釋和 Rust 程式碼範例能幫助您理解神經網路的核心概念！有什麼具體問題歡迎繼續詢問。
