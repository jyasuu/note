Yes, I can help you implement cross-thread notification to wake threads using Rust's standard library, without Tokio. Here are a few approaches:

## Using `std::sync::Condvar` (Recommended)

The most idiomatic way is using `Condvar` (condition variable) with a `Mutex`:

```rust
use std::sync::{Arc, Condvar, Mutex};
use std::thread;
use std::time::Duration;

fn main() {
    let pair = Arc::new((Mutex::new(false), Condvar::new()));
    let pair_clone = Arc::clone(&pair);

    // Spawn a thread that waits for notification
    let handle = thread::spawn(move || {
        let (lock, cvar) = &*pair_clone;
        let mut notified = lock.lock().unwrap();
        
        // Wait until notified
        while !*notified {
            println!("Thread waiting...");
            notified = cvar.wait(notified).unwrap();
        }
        
        println!("Thread woken up!");
    });

    // Main thread sleeps then notifies
    thread::sleep(Duration::from_secs(2));
    println!("Notifying thread...");
    
    let (lock, cvar) = &*pair;
    let mut notified = lock.lock().unwrap();
    *notified = true;
    cvar.notify_one(); // Or notify_all() for multiple waiters
    
    handle.join().unwrap();
}
```

## Using `std::sync::mpsc` Channel

Another approach using message passing:

```rust
use std::sync::mpsc;
use std::thread;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::channel();

    let handle = thread::spawn(move || {
        println!("Thread waiting for signal...");
        rx.recv().unwrap(); // Blocks until message received
        println!("Thread woken up!");
    });

    thread::sleep(Duration::from_secs(2));
    println!("Sending wake signal...");
    tx.send(()).unwrap(); // Send any value to wake

    handle.join().unwrap();
}
```

## Using `std::sync::atomic` with Polling

For a more lightweight approach (though less efficient due to polling):

```rust
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::thread;
use std::time::Duration;

fn main() {
    let wake_flag = Arc::new(AtomicBool::new(false));
    let wake_flag_clone = Arc::clone(&wake_flag);

    let handle = thread::spawn(move || {
        println!("Thread polling for wake signal...");
        while !wake_flag_clone.load(Ordering::Relaxed) {
            thread::sleep(Duration::from_millis(10)); // Polling interval
        }
        println!("Thread woken up!");
    });

    thread::sleep(Duration::from_secs(2));
    println!("Setting wake flag...");
    wake_flag.store(true, Ordering::Relaxed);

    handle.join().unwrap();
}
```

## Key Differences from Tokio:

- **Condvar**: Blocks the OS thread (not async), most similar to Tokio's `Notify`
- **Channel**: Message-based notification, blocks until message received
- **Atomic + polling**: Least efficient but most lightweight in terms of synchronization primitives

The `Condvar` approach is usually the best choice as it provides efficient blocking without busy-waiting and supports multiple waiters. It's the closest equivalent to Tokio's async notification mechanisms but for synchronous code.




You're right! The issue is likely a race condition. The main thread might be notifying before the worker thread has entered the `wait()` call. Here's the corrected version:The main issues with the original code were:

1. **Race condition**: The main thread might notify before the worker thread enters `wait()`
2. **Lock not properly released**: Should drop the mutex lock before calling `notify_one()`

Key fixes:
- Added a small delay to ensure the worker thread starts waiting first
- Properly scope the mutex lock so it's released before `notify_one()`
- The `while !*notified` loop ensures the thread keeps waiting until the condition is actually met

The `main_robust()` function shows a more sophisticated approach using a second condition variable to ensure proper synchronization without relying on timing.

Try running the `main_simple()` version - it should reliably print "Thread woken up!"


```rust
use std::sync::{Arc, Condvar, Mutex};
use std::thread;
use std::time::Duration;

fn main() {
    let pair = Arc::new((Mutex::new(false), Condvar::new()));
    let pair_clone = Arc::clone(&pair);

    // Spawn a thread that waits for notification
    let handle = thread::spawn(move || {
        let (lock, cvar) = &*pair_clone;
        let mut notified = lock.lock().unwrap();
        
        println!("Thread waiting...");
        // Wait until notified - this is the key fix
        while !*notified {
            notified = cvar.wait(notified).unwrap();
        }
        
        println!("Thread woken up!");
    });

    // Give the worker thread time to enter wait state
    thread::sleep(Duration::from_millis(100));
    
    println!("Notifying thread...");
    let (lock, cvar) = &*pair;
    {
        let mut notified = lock.lock().unwrap();
        *notified = true;
    } // Release lock before notify
    cvar.notify_one();
    
    handle.join().unwrap();
}

// Alternative: More robust version with proper synchronization
fn main_robust() {
    let pair = Arc::new((Mutex::new(false), Condvar::new()));
    let pair_clone = Arc::clone(&pair);
    let ready_pair = Arc::new((Mutex::new(false), Condvar::new()));
    let ready_pair_clone = Arc::clone(&ready_pair);

    // Spawn a thread that waits for notification
    let handle = thread::spawn(move || {
        let (lock, cvar) = &*pair_clone;
        let (ready_lock, ready_cvar) = &*ready_pair_clone;
        
        // Signal that we're ready to wait
        {
            let mut ready = ready_lock.lock().unwrap();
            *ready = true;
            ready_cvar.notify_one();
        }
        
        let mut notified = lock.lock().unwrap();
        println!("Thread waiting...");
        
        while !*notified {
            notified = cvar.wait(notified).unwrap();
        }
        
        println!("Thread woken up!");
    });

    // Wait for worker thread to be ready
    let (ready_lock, ready_cvar) = &*ready_pair;
    let mut ready = ready_lock.lock().unwrap();
    while !*ready {
        ready = ready_cvar.wait(ready).unwrap();
    }

    // Now we can safely notify
    thread::sleep(Duration::from_secs(2)); // Simulate some work
    println!("Notifying thread...");
    
    let (lock, cvar) = &*pair;
    {
        let mut notified = lock.lock().unwrap();
        *notified = true;
    }
    cvar.notify_one();
    
    handle.join().unwrap();
}

// Simpler working version - just ensure proper ordering
fn main_simple() {
    let pair = Arc::new((Mutex::new(false), Condvar::new()));
    let pair_clone = Arc::clone(&pair);

    let handle = thread::spawn(move || {
        let (lock, cvar) = &*pair_clone;
        let mut notified = lock.lock().unwrap();
        
        println!("Thread waiting...");
        
        // This loop ensures we wait even if notify comes before wait
        while !*notified {
            notified = cvar.wait(notified).unwrap();
        }
        
        println!("Thread woken up!");
    });

    // Ensure worker thread starts first
    thread::sleep(Duration::from_millis(100));
    
    // Simulate some work
    thread::sleep(Duration::from_secs(1));
    
    println!("About to notify thread...");
    
    // Notify the waiting thread
    let (lock, cvar) = &*pair;
    {
        let mut notified = lock.lock().unwrap();
        *notified = true;
        // Drop the lock before notify to avoid potential issues
    }
    cvar.notify_one();
    
    handle.join().unwrap();
    println!("Main thread finished");
}
```


Yes, I can help you implement a REST API in Rust that receives requests and waits for messages from a message broker. Here's how you can approach this pattern with different brokers:

## General Architecture

The typical pattern involves:
1. REST endpoint receives a request
2. Publishes a message or stores request info
3. Subscribes to a response topic/queue
4. Waits for a response message
5. Returns the response to the HTTP client

## Implementation Examples

### With Redis (using redis-rs and tokio)

```rust
use axum::{extract::State, http::StatusCode, response::Json, routing::post, Router};
use redis::{AsyncCommands, Client};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use tokio::time::{timeout, Duration};
use uuid::Uuid;

#[derive(Serialize, Deserialize)]
struct ProcessRequest {
    data: String,
}

#[derive(Serialize, Deserialize)]
struct ProcessResponse {
    id: String,
    result: String,
}

struct AppState {
    redis_client: Client,
}

async fn process_request(
    State(state): State<Arc<AppState>>,
    Json(payload): Json<ProcessRequest>,
) -> Result<Json<ProcessResponse>, StatusCode> {
    let mut conn = state.redis_client.get_async_connection().await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    
    // Generate unique request ID
    let request_id = Uuid::new_v4().to_string();
    
    // Publish request to processing queue
    let request_data = serde_json::json!({
        "id": request_id,
        "data": payload.data
    });
    
    conn.lpush::<_, _, ()>("processing_queue", request_data.to_string()).await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    
    // Wait for response on response channel
    let response_key = format!("response:{}", request_id);
    let result: Option<String> = timeout(
        Duration::from_secs(30),
        async {
            loop {
                let response: Option<String> = conn.get(&response_key).await.ok()?;
                if let Some(resp) = response {
                    conn.del::<_, ()>(&response_key).await.ok()?;
                    return Some(resp);
                }
                tokio::time::sleep(Duration::from_millis(100)).await;
            }
        }
    ).await.map_err(|_| StatusCode::REQUEST_TIMEOUT)??;
    
    if let Some(response_data) = result {
        let response: ProcessResponse = serde_json::from_str(&response_data)
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
        Ok(Json(response))
    } else {
        Err(StatusCode::REQUEST_TIMEOUT)
    }
}

#[tokio::main]
async fn main() {
    let redis_client = Client::open("redis://localhost:6379/").unwrap();
    let state = Arc::new(AppState { redis_client });
    
    let app = Router::new()
        .route("/process", post(process_request))
        .with_state(state);
    
    axum::Server::bind(&"0.0.0.0:3000".parse().unwrap())
        .serve(app.into_make_service())
        .await
        .unwrap();
}
```

### With Kafka (using rdkafka)

```rust
use axum::{extract::State, http::StatusCode, response::Json, routing::post, Router};
use rdkafka::{
    consumer::{Consumer, StreamConsumer},
    producer::{FutureProducer, FutureRecord},
    ClientConfig, Message,
};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use tokio::time::{timeout, Duration};
use uuid::Uuid;

#[derive(Serialize, Deserialize)]
struct ProcessRequest {
    data: String,
}

#[derive(Serialize, Deserialize)]
struct ProcessResponse {
    id: String,
    result: String,
}

struct AppState {
    producer: FutureProducer,
    consumer: StreamConsumer,
}

async fn process_request(
    State(state): State<Arc<AppState>>,
    Json(payload): Json<ProcessRequest>,
) -> Result<Json<ProcessResponse>, StatusCode> {
    let request_id = Uuid::new_v4().to_string();
    
    // Publish request to Kafka topic
    let request_data = serde_json::json!({
        "id": request_id,
        "data": payload.data
    });
    
    state.producer
        .send(
            FutureRecord::to("processing_requests")
                .key(&request_id)
                .payload(&request_data.to_string()),
            Duration::from_secs(5),
        )
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    
    // Wait for response message
    let result = timeout(Duration::from_secs(30), async {
        loop {
            if let Ok(message) = state.consumer.recv().await {
                if let Some(key) = message.key() {
                    if key == request_id.as_bytes() {
                        if let Some(payload) = message.payload() {
                            let response_str = std::str::from_utf8(payload).ok()?;
                            return serde_json::from_str::<ProcessResponse>(response_str).ok();
                        }
                    }
                }
            }
        }
    }).await;
    
    match result {
        Ok(Some(response)) => Ok(Json(response)),
        _ => Err(StatusCode::REQUEST_TIMEOUT),
    }
}

#[tokio::main]
async fn main() {
    let producer: FutureProducer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .create()
        .unwrap();
    
    let consumer: StreamConsumer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("group.id", "api_consumer")
        .set("auto.offset.reset", "latest")
        .create()
        .unwrap();
    
    consumer.subscribe(&["processing_responses"]).unwrap();
    
    let state = Arc::new(AppState { producer, consumer });
    
    let app = Router::new()
        .route("/process", post(process_request))
        .with_state(state);
    
    axum::Server::bind(&"0.0.0.0:3000".parse().unwrap())
        .serve(app.into_make_service())
        .await
        .unwrap();
}
```

### With RabbitMQ (using lapin)

```rust
use axum::{extract::State, http::StatusCode, response::Json, routing::post, Router};
use lapin::{
    options::*, types::FieldTable, BasicProperties, Connection, ConnectionProperties,
};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use tokio::time::{timeout, Duration};
use uuid::Uuid;

#[derive(Serialize, Deserialize)]
struct ProcessRequest {
    data: String,
}

#[derive(Serialize, Deserialize)]
struct ProcessResponse {
    id: String,
    result: String,
}

struct AppState {
    connection: Connection,
}

async fn process_request(
    State(state): State<Arc<AppState>>,
    Json(payload): Json<ProcessRequest>,
) -> Result<Json<ProcessResponse>, StatusCode> {
    let channel = state.connection.create_channel().await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    
    let request_id = Uuid::new_v4().to_string();
    
    // Declare queues
    let _request_queue = channel
        .queue_declare("processing_requests", QueueDeclareOptions::default(), FieldTable::default())
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    
    let response_queue_name = format!("response_{}", request_id);
    let _response_queue = channel
        .queue_declare(&response_queue_name, QueueDeclareOptions::default(), FieldTable::default())
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    
    // Publish request
    let request_data = serde_json::json!({
        "id": request_id,
        "data": payload.data,
        "reply_to": response_queue_name
    });
    
    channel
        .basic_publish(
            "",
            "processing_requests",
            BasicPublishOptions::default(),
            request_data.to_string().as_bytes(),
            BasicProperties::default(),
        )
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    
    // Consume response
    let mut consumer = channel
        .basic_consume(
            &response_queue_name,
            "api_consumer",
            BasicConsumeOptions::default(),
            FieldTable::default(),
        )
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    
    let result = timeout(Duration::from_secs(30), async {
        if let Some(delivery) = consumer.next().await {
            if let Ok(delivery) = delivery {
                let response_str = std::str::from_utf8(&delivery.data).ok()?;
                delivery.ack(BasicAckOptions::default()).await.ok()?;
                return serde_json::from_str::<ProcessResponse>(response_str).ok();
            }
        }
        None
    }).await;
    
    // Clean up response queue
    let _ = channel.queue_delete(&response_queue_name, QueueDeleteOptions::default()).await;
    
    match result {
        Ok(Some(response)) => Ok(Json(response)),
        _ => Err(StatusCode::REQUEST_TIMEOUT),
    }
}
```

## Key Dependencies

Add these to your `Cargo.toml`:

```toml
[dependencies]
axum = "0.7"
tokio = { version = "1.0", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
uuid = { version = "1.0", features = ["v4"] }

# For Redis
redis = { version = "0.24", features = ["tokio-comp"] }

# For Kafka
rdkafka = { version = "0.36", features = ["cmake-build"] }

# For RabbitMQ
lapin = "2.3"
```

## Important Considerations

1. **Timeout Handling**: Always set reasonable timeouts to prevent hanging requests
2. **Error Handling**: Implement proper error handling for broker connection issues
3. **Connection Pooling**: Consider using connection pools for better performance
4. **Message Correlation**: Use correlation IDs to match requests with responses
5. **Dead Letter Queues**: Implement DLQs for failed message processing
6. **Health Checks**: Add health check endpoints for your API and broker connections

The choice between brokers depends on your specific requirements:
- **Redis**: Simple pub/sub, good for caching and simple queuing
- **Kafka**: High throughput, event streaming, complex routing
- **RabbitMQ**: Feature-rich messaging, complex routing, reliability features

Would you like me to elaborate on any specific broker implementation or discuss patterns like request-reply vs publish-subscribe?

Great point! Separating the subscription logic from the request handler is a much better architectural pattern. This allows for persistent connections, better resource management, and cleaner separation of concerns. Here are implementations with the subscription behavior running independently:

## Redis Implementation with Background Subscriber## Kafka Implementation with Background Consumer## RabbitMQ Implementation with Background Consumer## Key Benefits of This Approach

1. **Persistent Connections**: Broker connections are established once and reused
2. **Better Resource Management**: No connection overhead per request
3. **Separation of Concerns**: Publisher/consumer logic is separate from HTTP handling
4. **Scalability**: Background tasks can handle high message throughput
5. **Reliability**: Connection failures are handled in background tasks

## Additional Patterns You Can Implement

### Connection Pool Pattern
```rust
// For better connection management
use deadpool_redis::{Config, Runtime};

let cfg = Config::from_url("redis://localhost:6379");
let pool = cfg.create_pool(Some(Runtime::Tokio1)).unwrap();
```

### Circuit Breaker Pattern
```rust
// Add circuit breaker for broker failures
use circuit_breaker::CircuitBreaker;

let breaker = CircuitBreaker::new(5, Duration::from_secs(60));
```

### Metrics and Monitoring
```rust
// Add metrics for monitoring
use prometheus::{Counter, Histogram};

lazy_static! {
    static ref REQUEST_COUNTER: Counter = Counter::new("requests_total", "Total requests").unwrap();
    static ref RESPONSE_TIME: Histogram = Histogram::new("response_time_seconds", "Response time").unwrap();
}
```

## Cargo.toml Dependencies

```toml
[dependencies]
axum = "0.7"
tokio = { version = "1.0", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
uuid = { version = "1.0", features = ["v4"] }
futures-util = "0.3"

# For Redis
redis = { version = "0.24", features = ["tokio-comp"] }

# For Kafka  
rdkafka = { version = "0.36", features = ["cmake-build"] }

# For RabbitMQ
lapin = "2.3"
```

This architecture is much more robust and production-ready. The background subscribers maintain persistent connections and handle message processing independently of HTTP requests, leading to better performance and reliability.

```rust
use axum::{extract::State, http::StatusCode, response::Json, routing::post, Router};
use redis::{AsyncCommands, Client};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{mpsc, oneshot, RwLock};
use tokio::time::{timeout, Duration};
use uuid::Uuid;

#[derive(Serialize, Deserialize, Clone)]
struct ProcessRequest {
    data: String,
}

#[derive(Serialize, Deserialize, Clone)]
struct ProcessResponse {
    id: String,
    result: String,
}

// Channel for waiting requests
type PendingRequests = Arc<RwLock<HashMap<String, oneshot::Sender<ProcessResponse>>>>;

#[derive(Clone)]
struct AppState {
    redis_client: Client,
    pending_requests: PendingRequests,
    request_sender: mpsc::Sender<ProcessRequest>,
}

// Background subscriber task
async fn redis_subscriber_task(
    redis_client: Client,
    pending_requests: PendingRequests,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    let mut conn = redis_client.get_async_connection().await?;
    
    loop {
        // Poll for responses using BLPOP (blocking list pop)
        let result: Option<(String, String)> = conn
            .blpop("processing_responses", 1)
            .await
            .unwrap_or(None);
        
        if let Some((_, response_data)) = result {
            if let Ok(response) = serde_json::from_str::<ProcessResponse>(&response_data) {
                let mut pending = pending_requests.write().await;
                if let Some(sender) = pending.remove(&response.id) {
                    let _ = sender.send(response);
                }
            }
        }
        
        tokio::task::yield_now().await;
    }
}

// Background publisher task
async fn redis_publisher_task(
    redis_client: Client,
    mut request_receiver: mpsc::Receiver<ProcessRequest>,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    let mut conn = redis_client.get_async_connection().await?;
    
    while let Some(request) = request_receiver.recv().await {
        let request_data = serde_json::to_string(&request)?;
        let _: () = conn.lpush("processing_queue", request_data).await?;
    }
    
    Ok(())
}

async fn process_request(
    State(state): State<AppState>,
    Json(payload): Json<ProcessRequest>,
) -> Result<Json<ProcessResponse>, StatusCode> {
    let request_id = Uuid::new_v4().to_string();
    let (response_sender, response_receiver) = oneshot::channel();
    
    // Add to pending requests
    {
        let mut pending = state.pending_requests.write().await;
        pending.insert(request_id.clone(), response_sender);
    }
    
    // Create request with ID
    let mut request_with_id = payload;
    let request_data = serde_json::json!({
        "id": request_id,
        "data": request_with_id.data
    });
    
    // Send to publisher
    if let Ok(request) = serde_json::from_value(request_data) {
        state.request_sender.send(request).await
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    }
    
    // Wait for response with timeout
    match timeout(Duration::from_secs(30), response_receiver).await {
        Ok(Ok(response)) => Ok(Json(response)),
        Ok(Err(_)) => {
            // Clean up pending request
            let mut pending = state.pending_requests.write().await;
            pending.remove(&request_id);
            Err(StatusCode::INTERNAL_SERVER_ERROR)
        }
        Err(_) => {
            // Timeout - clean up pending request
            let mut pending = state.pending_requests.write().await;
            pending.remove(&request_id);
            Err(StatusCode::REQUEST_TIMEOUT)
        }
    }
}

async fn health_check() -> &'static str {
    "OK"
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let redis_client = Client::open("redis://localhost:6379/")?;
    let pending_requests: PendingRequests = Arc::new(RwLock::new(HashMap::new()));
    let (request_sender, request_receiver) = mpsc::channel::<ProcessRequest>(100);
    
    let state = AppState {
        redis_client: redis_client.clone(),
        pending_requests: pending_requests.clone(),
        request_sender,
    };
    
    // Start background tasks
    let subscriber_handle = tokio::spawn(redis_subscriber_task(
        redis_client.clone(),
        pending_requests.clone(),
    ));
    
    let publisher_handle = tokio::spawn(redis_publisher_task(
        redis_client.clone(),
        request_receiver,
    ));
    
    // Setup HTTP server
    let app = Router::new()
        .route("/process", post(process_request))
        .route("/health", axum::routing::get(health_check))
        .with_state(state);
    
    println!("Server starting on http://0.0.0.0:3000");
    
    // Start server
    let server_handle = tokio::spawn(async move {
        axum::Server::bind(&"0.0.0.0:3000".parse().unwrap())
            .serve(app.into_make_service())
            .await
            .unwrap();
    });
    
    // Wait for any task to complete (or fail)
    tokio::select! {
        _ = subscriber_handle => println!("Subscriber task ended"),
        _ = publisher_handle => println!("Publisher task ended"),
        _ = server_handle => println!("Server ended"),
    }
    
    Ok(())
}
```


```rust
use axum::{extract::State, http::StatusCode, response::Json, routing::post, Router};
use rdkafka::{
    consumer::{Consumer, StreamConsumer},
    producer::{FutureProducer, FutureRecord},
    ClientConfig, Message,
};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{mpsc, oneshot, RwLock};
use tokio::time::{timeout, Duration};
use uuid::Uuid;

#[derive(Serialize, Deserialize, Clone)]
struct ProcessRequest {
    id: String,
    data: String,
}

#[derive(Serialize, Deserialize, Clone)]
struct ProcessResponse {
    id: String,
    result: String,
}

#[derive(Serialize, Deserialize)]
struct ApiRequest {
    data: String,
}

// Channel for waiting requests
type PendingRequests = Arc<RwLock<HashMap<String, oneshot::Sender<ProcessResponse>>>>;

#[derive(Clone)]
struct AppState {
    producer: Arc<FutureProducer>,
    pending_requests: PendingRequests,
}

// Background consumer task
async fn kafka_consumer_task(
    consumer: StreamConsumer,
    pending_requests: PendingRequests,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    consumer.subscribe(&["processing_responses"])?;
    
    loop {
        match consumer.recv().await {
            Ok(message) => {
                if let Some(payload) = message.payload() {
                    if let Ok(response_str) = std::str::from_utf8(payload) {
                        if let Ok(response) = serde_json::from_str::<ProcessResponse>(response_str) {
                            let mut pending = pending_requests.write().await;
                            if let Some(sender) = pending.remove(&response.id) {
                                let _ = sender.send(response);
                            }
                        }
                    }
                }
                // Commit the message
                consumer.commit_message(&message, rdkafka::consumer::CommitMode::Async)?;
            }
            Err(e) => {
                eprintln!("Kafka consumer error: {:?}", e);
                tokio::time::sleep(Duration::from_millis(100)).await;
            }
        }
    }
}

async fn process_request(
    State(state): State<AppState>,
    Json(payload): Json<ApiRequest>,
) -> Result<Json<ProcessResponse>, StatusCode> {
    let request_id = Uuid::new_v4().to_string();
    let (response_sender, response_receiver) = oneshot::channel();
    
    // Add to pending requests
    {
        let mut pending = state.pending_requests.write().await;
        pending.insert(request_id.clone(), response_sender);
    }
    
    // Create and send request
    let request = ProcessRequest {
        id: request_id.clone(),
        data: payload.data,
    };
    
    let request_json = serde_json::to_string(&request)
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    
    // Send to Kafka
    let delivery_status = state
        .producer
        .send(
            FutureRecord::to("processing_requests")
                .key(&request_id)
                .payload(&request_json),
            Duration::from_secs(5),
        )
        .await;
    
    if delivery_status.is_err() {
        // Clean up pending request
        let mut pending = state.pending_requests.write().await;
        pending.remove(&request_id);
        return Err(StatusCode::INTERNAL_SERVER_ERROR);
    }
    
    // Wait for response with timeout
    match timeout(Duration::from_secs(30), response_receiver).await {
        Ok(Ok(response)) => Ok(Json(response)),
        Ok(Err(_)) => {
            // Clean up pending request
            let mut pending = state.pending_requests.write().await;
            pending.remove(&request_id);
            Err(StatusCode::INTERNAL_SERVER_ERROR)
        }
        Err(_) => {
            // Timeout - clean up pending request
            let mut pending = state.pending_requests.write().await;
            pending.remove(&request_id);
            Err(StatusCode::REQUEST_TIMEOUT)
        }
    }
}

async fn health_check() -> &'static str {
    "OK"
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Create producer
    let producer: FutureProducer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("message.timeout.ms", "5000")
        .create()?;
    
    // Create consumer
    let consumer: StreamConsumer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("group.id", "api_consumer_group")
        .set("auto.offset.reset", "latest")
        .set("enable.partition.eof", "false")
        .set("session.timeout.ms", "6000")
        .set("enable.auto.commit", "false")
        .create()?;
    
    let pending_requests: PendingRequests = Arc::new(RwLock::new(HashMap::new()));
    
    let state = AppState {
        producer: Arc::new(producer),
        pending_requests: pending_requests.clone(),
    };
    
    // Start background consumer task
    let consumer_handle = tokio::spawn(kafka_consumer_task(
        consumer,
        pending_requests.clone(),
    ));
    
    // Setup HTTP server
    let app = Router::new()
        .route("/process", post(process_request))
        .route("/health", axum::routing::get(health_check))
        .with_state(state);
    
    println!("Server starting on http://0.0.0.0:3000");
    
    // Start server
    let server_handle = tokio::spawn(async move {
        axum::Server::bind(&"0.0.0.0:3000".parse().unwrap())
            .serve(app.into_make_service())
            .await
            .unwrap();
    });
    
    // Wait for any task to complete (or fail)
    tokio::select! {
        result = consumer_handle => {
            println!("Consumer task ended: {:?}", result);
        }
        _ = server_handle => {
            println!("Server ended");
        }
    }
    
    Ok(())
}
```


```rust
use axum::{extract::State, http::StatusCode, response::Json, routing::post, Router};
use futures_util::stream::StreamExt;
use lapin::{
    options::*, types::FieldTable, BasicProperties, Channel, Connection, ConnectionProperties,
};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{mpsc, oneshot, RwLock};
use tokio::time::{timeout, Duration};
use uuid::Uuid;

#[derive(Serialize, Deserialize, Clone)]
struct ProcessRequest {
    id: String,
    data: String,
}

#[derive(Serialize, Deserialize, Clone)]
struct ProcessResponse {
    id: String,
    result: String,
}

#[derive(Serialize, Deserialize)]
struct ApiRequest {
    data: String,
}

// Channel for waiting requests
type PendingRequests = Arc<RwLock<HashMap<String, oneshot::Sender<ProcessResponse>>>>;

#[derive(Clone)]
struct AppState {
    channel: Arc<Channel>,
    pending_requests: PendingRequests,
}

// Background consumer task
async fn rabbitmq_consumer_task(
    channel: Channel,
    pending_requests: PendingRequests,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    // Declare the response queue
    let _queue = channel
        .queue_declare(
            "processing_responses",
            QueueDeclareOptions::default(),
            FieldTable::default(),
        )
        .await?;
    
    // Create consumer
    let mut consumer = channel
        .basic_consume(
            "processing_responses",
            "api_consumer",
            BasicConsumeOptions::default(),
            FieldTable::default(),
        )
        .await?;
    
    println!("RabbitMQ consumer started, waiting for messages...");
    
    while let Some(delivery) = consumer.next().await {
        match delivery {
            Ok(delivery) => {
                if let Ok(response_str) = std::str::from_utf8(&delivery.data) {
                    if let Ok(response) = serde_json::from_str::<ProcessResponse>(response_str) {
                        let mut pending = pending_requests.write().await;
                        if let Some(sender) = pending.remove(&response.id) {
                            let _ = sender.send(response);
                        }
                    }
                }
                
                // Acknowledge the message
                if let Err(e) = delivery.ack(BasicAckOptions::default()).await {
                    eprintln!("Failed to ack message: {:?}", e);
                }
            }
            Err(e) => {
                eprintln!("RabbitMQ consumer error: {:?}", e);
                tokio::time::sleep(Duration::from_millis(100)).await;
            }
        }
    }
    
    Ok(())
}

async fn process_request(
    State(state): State<AppState>,
    Json(payload): Json<ApiRequest>,
) -> Result<Json<ProcessResponse>, StatusCode> {
    let request_id = Uuid::new_v4().to_string();
    let (response_sender, response_receiver) = oneshot::channel();
    
    // Add to pending requests
    {
        let mut pending = state.pending_requests.write().await;
        pending.insert(request_id.clone(), response_sender);
    }
    
    // Create request
    let request = ProcessRequest {
        id: request_id.clone(),
        data: payload.data,
    };
    
    let request_json = serde_json::to_string(&request)
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    
    // Publish to RabbitMQ
    let publish_result = state
        .channel
        .basic_publish(
            "",
            "processing_requests",
            BasicPublishOptions::default(),
            request_json.as_bytes(),
            BasicProperties::default(),
        )
        .await;
    
    if publish_result.is_err() {
        // Clean up pending request
        let mut pending = state.pending_requests.write().await;
        pending.remove(&request_id);
        return Err(StatusCode::INTERNAL_SERVER_ERROR);
    }
    
    // Wait for response with timeout
    match timeout(Duration::from_secs(30), response_receiver).await {
        Ok(Ok(response)) => Ok(Json(response)),
        Ok(Err(_)) => {
            // Clean up pending request
            let mut pending = state.pending_requests.write().await;
            pending.remove(&request_id);
            Err(StatusCode::INTERNAL_SERVER_ERROR)
        }
        Err(_) => {
            // Timeout - clean up pending request
            let mut pending = state.pending_requests.write().await;
            pending.remove(&request_id);
            Err(StatusCode::REQUEST_TIMEOUT)
        }
    }
}

async fn health_check() -> &'static str {
    "OK"
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Connect to RabbitMQ
    let connection = Connection::connect(
        "amqp://localhost:5672",
        ConnectionProperties::default(),
    )
    .await?;
    
    let channel = connection.create_channel().await?;
    
    // Declare queues
    let _request_queue = channel
        .queue_declare(
            "processing_requests",
            QueueDeclareOptions::default(),
            FieldTable::default(),
        )
        .await?;
    
    let _response_queue = channel
        .queue_declare(
            "processing_responses",
            QueueDeclareOptions::default(),
            FieldTable::default(),
        )
        .await?;
    
    let pending_requests: PendingRequests = Arc::new(RwLock::new(HashMap::new()));
    
    let state = AppState {
        channel: Arc::new(channel.clone()),
        pending_requests: pending_requests.clone(),
    };
    
    // Start background consumer task
    let consumer_handle = tokio::spawn(rabbitmq_consumer_task(
        channel,
        pending_requests.clone(),
    ));
    
    // Setup HTTP server
    let app = Router::new()
        .route("/process", post(process_request))
        .route("/health", axum::routing::get(health_check))
        .with_state(state);
    
    println!("Server starting on http://0.0.0.0:3000");
    
    // Start server
    let server_handle = tokio::spawn(async move {
        axum::Server::bind(&"0.0.0.0:3000".parse().unwrap())
            .serve(app.into_make_service())
            .await
            .unwrap();
    });
    
    // Wait for any task to complete (or fail)
    tokio::select! {
        result = consumer_handle => {
            println!("Consumer task ended: {:?}", result);
        }
        _ = server_handle => {
            println!("Server ended");
        }
    }
    
    Ok(())
}
```
