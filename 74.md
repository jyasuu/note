I'll help you implement a Gemini RAG system in Rust without external dependencies. You're right that RAG involves ranking embedding vectors and retrieving top-k relevant information. Let me create a complete implementation for you.I've created a complete Gemini RAG implementation in Rust that meets your requirements. Here's what the code provides:

## Key Features:

1. **No External Dependencies**: Uses only an in-memory vector store, no database required
2. **Embedding Generation**: Integrates with Gemini's embedding API
3. **Vector Similarity Search**: Implements cosine similarity for ranking
4. **Top-K Retrieval**: Returns the most relevant documents based on similarity scores
5. **RAG Pipeline**: Combines retrieval with generation for contextual answers

## Core Components:

- **`VectorStore`**: In-memory storage for documents and embeddings
- **`GeminiClient`**: Handles API calls to Gemini for embeddings and text generation
- **`GeminiRAG`**: Main RAG system that orchestrates retrieval and generation
- **`Document`**: Structure for storing text, embeddings, and metadata

## Usage:

1. Set your Gemini API key as an environment variable: `GEMINI_API_KEY`
2. Add documents to the knowledge base using `add_document()`
3. Query the system using `generate_answer()` for RAG responses
4. Or use `retrieve()` for just document retrieval

## Key Methods:

- `add_document()`: Adds documents with automatic embedding generation
- `retrieve()`: Finds top-k similar documents for a query
- `generate_answer()`: Full RAG pipeline - retrieves context and generates answer
- `cosine_similarity()`: Calculates similarity between embedding vectors

The implementation uses cosine similarity for ranking embeddings and maintains everything in memory, making it suitable for smaller knowledge bases without requiring external database setup. The system automatically handles embedding generation through Gemini's API and provides a clean interface for both retrieval and generation tasks.



```rs
use std::collections::HashMap;
use std::error::Error;
use std::fmt;

// Custom error type for RAG operations
#[derive(Debug)]
pub enum RagError {
    ApiError(String),
    EmbeddingError(String),
    InvalidInput(String),
}

impl fmt::Display for RagError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            RagError::ApiError(msg) => write!(f, "API Error: {}", msg),
            RagError::EmbeddingError(msg) => write!(f, "Embedding Error: {}", msg),
            RagError::InvalidInput(msg) => write!(f, "Invalid Input: {}", msg),
        }
    }
}

impl Error for RagError {}

// Document structure to store text and its embedding
#[derive(Debug, Clone)]
pub struct Document {
    pub id: String,
    pub text: String,
    pub embedding: Vec<f32>,
    pub metadata: HashMap<String, String>,
}

// Similarity score with document reference
#[derive(Debug, Clone)]
pub struct SimilarityResult {
    pub document: Document,
    pub score: f32,
}

// In-memory vector store
pub struct VectorStore {
    documents: Vec<Document>,
    dimension: usize,
}

impl VectorStore {
    pub fn new(dimension: usize) -> Self {
        Self {
            documents: Vec::new(),
            dimension,
        }
    }

    pub fn add_document(&mut self, document: Document) -> Result<(), RagError> {
        if document.embedding.len() != self.dimension {
            return Err(RagError::EmbeddingError(
                format!("Expected embedding dimension {}, got {}", 
                       self.dimension, document.embedding.len())
            ));
        }
        self.documents.push(document);
        Ok(())
    }

    pub fn search(&self, query_embedding: &[f32], k: usize) -> Result<Vec<SimilarityResult>, RagError> {
        if query_embedding.len() != self.dimension {
            return Err(RagError::EmbeddingError(
                format!("Query embedding dimension {} doesn't match store dimension {}", 
                       query_embedding.len(), self.dimension)
            ));
        }

        let mut similarities: Vec<SimilarityResult> = self.documents
            .iter()
            .map(|doc| {
                let score = cosine_similarity(query_embedding, &doc.embedding);
                SimilarityResult {
                    document: doc.clone(),
                    score,
                }
            })
            .collect();

        // Sort by similarity score in descending order
        similarities.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap_or(std::cmp::Ordering::Equal));

        // Return top k results
        Ok(similarities.into_iter().take(k).collect())
    }

    pub fn len(&self) -> usize {
        self.documents.len()
    }
}

// Gemini API client
pub struct GeminiClient {
    api_key: String,
    base_url: String,
}

impl GeminiClient {
    pub fn new(api_key: String) -> Self {
        Self {
            api_key,
            base_url: "https://generativelanguage.googleapis.com/v1beta".to_string(),
        }
    }

    // Generate embedding for text using Gemini API
    pub async fn generate_embedding(&self, text: &str) -> Result<Vec<f32>, RagError> {
        let client = reqwest::Client::new();
        let url = format!("{}/models/embedding-001:embedContent?key={}", 
                         self.base_url, self.api_key);

        let request_body = serde_json::json!({
            "content": {
                "parts": [{"text": text}]
            }
        });

        let response = client
            .post(&url)
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .map_err(|e| RagError::ApiError(e.to_string()))?;

        if !response.status().is_success() {
            let error_text = response.text().await.unwrap_or_default();
            return Err(RagError::ApiError(format!("API request failed: {}", error_text)));
        }

        let response_json: serde_json::Value = response
            .json()
            .await
            .map_err(|e| RagError::ApiError(e.to_string()))?;

        let embedding = response_json["embedding"]["values"]
            .as_array()
            .ok_or_else(|| RagError::ApiError("Invalid embedding response format".to_string()))?
            .iter()
            .map(|v| v.as_f64().unwrap_or(0.0) as f32)
            .collect();

        Ok(embedding)
    }

    // Generate text using Gemini API
    pub async fn generate_text(&self, prompt: &str) -> Result<String, RagError> {
        let client = reqwest::Client::new();
        let url = format!("{}/models/gemini-pro:generateContent?key={}", 
                         self.base_url, self.api_key);

        let request_body = serde_json::json!({
            "contents": [{
                "parts": [{"text": prompt}]
            }]
        });

        let response = client
            .post(&url)
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .map_err(|e| RagError::ApiError(e.to_string()))?;

        if !response.status().is_success() {
            let error_text = response.text().await.unwrap_or_default();
            return Err(RagError::ApiError(format!("API request failed: {}", error_text)));
        }

        let response_json: serde_json::Value = response
            .json()
            .await
            .map_err(|e| RagError::ApiError(e.to_string()))?;

        let text = response_json["candidates"][0]["content"]["parts"][0]["text"]
            .as_str()
            .ok_or_else(|| RagError::ApiError("Invalid text generation response format".to_string()))?
            .to_string();

        Ok(text)
    }
}

// Main RAG system
pub struct GeminiRAG {
    client: GeminiClient,
    vector_store: VectorStore,
}

impl GeminiRAG {
    pub fn new(api_key: String, embedding_dimension: usize) -> Self {
        Self {
            client: GeminiClient::new(api_key),
            vector_store: VectorStore::new(embedding_dimension),
        }
    }

    // Add document to the knowledge base
    pub async fn add_document(&mut self, id: String, text: String, metadata: HashMap<String, String>) -> Result<(), RagError> {
        let embedding = self.client.generate_embedding(&text).await?;
        
        let document = Document {
            id,
            text,
            embedding,
            metadata,
        };

        self.vector_store.add_document(document)
    }

    // Retrieve relevant documents for a query
    pub async fn retrieve(&self, query: &str, k: usize) -> Result<Vec<SimilarityResult>, RagError> {
        let query_embedding = self.client.generate_embedding(query).await?;
        self.vector_store.search(&query_embedding, k)
    }

    // Generate answer using RAG approach
    pub async fn generate_answer(&self, query: &str, k: usize) -> Result<String, RagError> {
        // Retrieve relevant documents
        let relevant_docs = self.retrieve(query, k).await?;

        if relevant_docs.is_empty() {
            return Err(RagError::InvalidInput("No relevant documents found".to_string()));
        }

        // Build context from retrieved documents
        let context = relevant_docs
            .iter()
            .map(|result| format!("Document (score: {:.3}): {}", result.score, result.document.text))
            .collect::<Vec<_>>()
            .join("\n\n");

        // Create prompt with context
        let prompt = format!(
            "Based on the following context, please answer the question.\n\nContext:\n{}\n\nQuestion: {}\n\nAnswer:",
            context, query
        );

        // Generate answer using Gemini
        self.client.generate_text(&prompt).await
    }

    pub fn document_count(&self) -> usize {
        self.vector_store.len()
    }
}

// Utility function to calculate cosine similarity
fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();
    
    if norm_a == 0.0 || norm_b == 0.0 {
        0.0
    } else {
        dot_product / (norm_a * norm_b)
    }
}

// Example usage
#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    // Initialize RAG system
    let api_key = std::env::var("GEMINI_API_KEY")
        .expect("GEMINI_API_KEY environment variable not set");
    
    let mut rag = GeminiRAG::new(api_key, 768); // Gemini embedding dimension

    // Add documents to knowledge base
    let mut metadata = HashMap::new();
    metadata.insert("source".to_string(), "doc1".to_string());
    
    rag.add_document(
        "doc1".to_string(),
        "Rust is a systems programming language that runs fast and prevents segfaults.".to_string(),
        metadata.clone()
    ).await?;

    metadata.insert("source".to_string(), "doc2".to_string());
    rag.add_document(
        "doc2".to_string(),
        "Machine learning involves training algorithms on data to make predictions.".to_string(),
        metadata.clone()
    ).await?;

    metadata.insert("source".to_string(), "doc3".to_string());
    rag.add_document(
        "doc3".to_string(),
        "Vector databases store high-dimensional embeddings for similarity search.".to_string(),
        metadata
    ).await?;

    println!("Added {} documents to knowledge base", rag.document_count());

    // Query the RAG system
    let query = "What is Rust programming language?";
    let answer = rag.generate_answer(query, 2).await?;
    
    println!("Query: {}", query);
    println!("Answer: {}", answer);

    // Retrieve similar documents
    let similar_docs = rag.retrieve("programming language", 2).await?;
    println!("\nSimilar documents:");
    for result in similar_docs {
        println!("Score: {:.3}, Text: {}", result.score, result.document.text);
    }

    Ok(())
}

// Add these dependencies to your Cargo.toml:
/*
[dependencies]
tokio = { version = "1.0", features = ["full"] }
reqwest = { version = "0.11", features = ["json"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
*/
```
