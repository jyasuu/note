# State-of-the-Art Rust Development Guide

## Modern Rust Architecture Patterns

### 1. Async-First Design
```rust
// Modern async patterns with tokio
use tokio::{sync::mpsc, task, time};
use futures::stream::StreamExt;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let (tx, mut rx) = mpsc::channel(100);
    
    // Structured concurrency
    let handle = task::spawn(async move {
        while let Some(msg) = rx.recv().await {
            process_message(msg).await;
        }
    });
    
    // Graceful shutdown patterns
    tokio::select! {
        _ = handle => {},
        _ = tokio::signal::ctrl_c() => {
            println!("Shutting down gracefully...");
        }
    }
    
    Ok(())
}
```

### 2. Type-Driven Development
```rust
// Leverage Rust's type system for correctness
use std::marker::PhantomData;

struct UserId(u64);
struct ProductId(u64);

// State machines in types
struct Unverified;
struct Verified;

struct User<State> {
    id: UserId,
    email: String,
    _state: PhantomData<State>,
}

impl User<Unverified> {
    fn verify(self) -> User<Verified> {
        User {
            id: self.id,
            email: self.email,
            _state: PhantomData,
        }
    }
}

impl User<Verified> {
    fn can_purchase(&self) -> bool { true }
}
```

### 3. Error Handling Excellence
```rust
use thiserror::Error;
use anyhow::{Context, Result};

#[derive(Error, Debug)]
pub enum AppError {
    #[error("Database connection failed")]
    DatabaseError(#[from] sqlx::Error),
    
    #[error("Validation failed: {message}")]
    ValidationError { message: String },
    
    #[error("External API error: {status}")]
    ApiError { status: u16 },
}

// Result extensions for better error context
fn process_user_data(data: &str) -> Result<ProcessedData> {
    let parsed = parse_data(data)
        .context("Failed to parse user input")?;
    
    validate_data(&parsed)
        .context("Data validation failed")?;
    
    Ok(transform_data(parsed))
}
```

## Cutting-Edge Crate Ecosystem

### Web Development
- **axum**: Modern, ergonomic web framework
- **tower**: Middleware and service abstractions
- **hyper**: HTTP implementation
- **tokio**: Async runtime

### Database & Storage
- **sqlx**: Compile-time checked SQL
- **sea-orm**: Modern ORM with migrations
- **surrealdb**: Multi-model database
- **redb**: Embedded key-value store

### Observability
- **tracing**: Structured logging and distributed tracing
- **metrics**: Application metrics
- **opentelemetry**: Observability standards

### Performance & Concurrency
- **rayon**: Data parallelism
- **crossbeam**: Lock-free data structures
- **parking_lot**: Faster synchronization primitives
- **dashmap**: Concurrent HashMap

## Modern Application Examples

### 1. High-Performance Web API
```rust
use axum::{
    extract::{Path, State},
    http::StatusCode,
    response::Json,
    routing::{get, post},
    Router,
};
use sqlx::PgPool;
use serde::{Deserialize, Serialize};
use tracing::{info, instrument};

#[derive(Clone)]
struct AppState {
    db: PgPool,
}

#[derive(Serialize, Deserialize)]
struct CreateUser {
    email: String,
    name: String,
}

#[instrument(skip(state))]
async fn create_user(
    State(state): State<AppState>,
    Json(payload): Json<CreateUser>,
) -> Result<Json<User>, StatusCode> {
    let user = sqlx::query_as!(
        User,
        "INSERT INTO users (email, name) VALUES ($1, $2) RETURNING *",
        payload.email,
        payload.name
    )
    .fetch_one(&state.db)
    .await
    .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    info!("Created user: {}", user.id);
    Ok(Json(user))
}

pub fn create_app(state: AppState) -> Router {
    Router::new()
        .route("/users", post(create_user))
        .route("/users/:id", get(get_user))
        .with_state(state)
        .layer(
            tower::ServiceBuilder::new()
                .layer(tower_http::trace::TraceLayer::new_for_http())
                .layer(tower_http::cors::CorsLayer::permissive())
        )
}
```

### 2. Real-time Data Processing
```rust
use tokio_stream::{wrappers::ReceiverStream, StreamExt};
use futures::stream::Stream;

struct DataProcessor {
    input: mpsc::Receiver<RawData>,
    output: mpsc::Sender<ProcessedData>,
}

impl DataProcessor {
    async fn run(mut self) {
        let stream = ReceiverStream::new(self.input)
            .map(|data| self.process_item(data))
            .buffer_unordered(100) // Process up to 100 items concurrently
            .filter_map(|result| async move { result.ok() });

        tokio::pin!(stream);
        
        while let Some(processed) = stream.next().await {
            if self.output.send(processed).await.is_err() {
                break; // Receiver dropped
            }
        }
    }
    
    async fn process_item(&self, data: RawData) -> Result<ProcessedData, ProcessingError> {
        // Complex async processing logic
        let enriched = enrich_data(data).await?;
        let validated = validate_data(enriched)?;
        let transformed = transform_data(validated).await?;
        
        Ok(transformed)
    }
}
```

### 3. CLI Tool with Modern UX
```rust
use clap::{Parser, Subcommand};
use indicatif::{ProgressBar, ProgressStyle};
use tokio::fs;
use anyhow::Result;

#[derive(Parser)]
#[command(name = "modern-cli")]
#[command(about = "A state-of-the-art CLI tool")]
struct Cli {
    #[command(subcommand)]
    command: Commands,
    
    #[arg(short, long, action = clap::ArgAction::Count)]
    verbose: u8,
}

#[derive(Subcommand)]
enum Commands {
    Process {
        #[arg(short, long)]
        input: PathBuf,
        #[arg(short, long)]
        output: PathBuf,
    },
    Analyze {
        path: PathBuf,
    },
}

#[tokio::main]
async fn main() -> Result<()> {
    let cli = Cli::parse();
    
    tracing_subscriber::fmt()
        .with_max_level(match cli.verbose {
            0 => tracing::Level::ERROR,
            1 => tracing::Level::WARN,
            2 => tracing::Level::INFO,
            _ => tracing::Level::DEBUG,
        })
        .init();

    match cli.command {
        Commands::Process { input, output } => {
            process_files(&input, &output).await?;
        }
        Commands::Analyze { path } => {
            analyze_directory(&path).await?;
        }
    }
    
    Ok(())
}

async fn process_files(input: &Path, output: &Path) -> Result<()> {
    let pb = ProgressBar::new_spinner();
    pb.set_style(ProgressStyle::default_spinner()
        .template("{spinner:.green} {msg}")?);
    
    pb.set_message("Processing files...");
    
    // Async file processing with progress updates
    let entries = fs::read_dir(input).await?;
    // ... processing logic
    
    pb.finish_with_message("✅ Processing complete!");
    Ok(())
}
```

## Performance Optimization Techniques

### 1. Memory Management
```rust
// Use Box for heap allocation when needed
use std::collections::HashMap;

// Pool expensive resources
struct ConnectionPool {
    connections: Vec<Connection>,
    available: Arc<Mutex<Vec<Connection>>>,
}

// Zero-copy string processing
fn process_str(s: &str) -> &str {
    s.trim_start_matches(char::is_whitespace)
}

// Efficient data structures
use ahash::AHashMap; // Faster than std HashMap
use smallvec::SmallVec; // Stack-allocated vectors for small sizes
```

### 2. Async Optimization
```rust
// Batch operations
async fn batch_process(items: Vec<Item>) -> Result<Vec<ProcessedItem>> {
    let futures: Vec<_> = items.into_iter()
        .map(|item| process_item(item))
        .collect();
    
    // Process all concurrently
    let results = futures::future::try_join_all(futures).await?;
    Ok(results)
}

// Connection pooling
use sqlx::PgPool;

let pool = PgPool::connect_with(
    PgConnectOptions::new()
        .max_connections(20)
        .acquire_timeout(Duration::from_secs(3))
).await?;
```

## Testing Excellence

### 1. Property-Based Testing
```rust
use proptest::prelude::*;

proptest! {
    #[test]
    fn test_serialization_roundtrip(data: MyStruct) {
        let serialized = serialize(&data)?;
        let deserialized = deserialize(&serialized)?;
        prop_assert_eq!(data, deserialized);
    }
}
```

### 2. Integration Testing
```rust
#[cfg(test)]
mod tests {
    use super::*;
    use testcontainers::{clients::Cli, images::postgres::Postgres, Docker};

    #[tokio::test]
    async fn test_database_operations() {
        let docker = Cli::default();
        let postgres = docker.run(Postgres::default());
        
        let connection_string = format!(
            "postgres://postgres@localhost:{}/postgres",
            postgres.get_host_port_ipv4(5432)
        );
        
        let pool = PgPool::connect(&connection_string).await.unwrap();
        
        // Run your tests against real database
        let result = create_user(&pool, "test@example.com").await;
        assert!(result.is_ok());
    }
}
```

## Deployment & Operations

### 1. Docker Optimization
```dockerfile
# Multi-stage build for minimal images
FROM rust:1.75 as builder
WORKDIR /app
COPY Cargo.toml Cargo.lock ./
RUN cargo fetch

COPY src ./src
RUN cargo build --release --offline

FROM gcr.io/distroless/cc-debian12
COPY --from=builder /app/target/release/myapp /
CMD ["./myapp"]
```

### 2. Observability
```rust
use tracing::{info, warn, error, instrument};
use metrics::{counter, histogram, gauge};

#[instrument(skip(db), fields(user_id = %user_id))]
async fn process_user_action(db: &Database, user_id: UserId, action: Action) -> Result<()> {
    let start = std::time::Instant::now();
    
    counter!("user_actions_total", "action" => action.name()).increment(1);
    
    let result = match action {
        Action::Purchase(item) => {
            info!("Processing purchase for item: {}", item.id);
            process_purchase(db, user_id, item).await
        }
        Action::UpdateProfile(data) => {
            info!("Updating user profile");
            update_profile(db, user_id, data).await
        }
    };
    
    let duration = start.elapsed();
    histogram!("action_duration_seconds", "action" => action.name())
        .record(duration.as_secs_f64());
    
    match &result {
        Ok(_) => counter!("user_actions_success_total").increment(1),
        Err(e) => {
            error!("Action failed: {}", e);
            counter!("user_actions_error_total").increment(1);
        }
    }
    
    result
}
```

This guide covers the essential patterns and tools for building state-of-the-art Rust applications. The key is leveraging Rust's type system, async capabilities, and rich ecosystem while following modern architectural patterns.



```rust
// Cargo.toml dependencies:
/*
[dependencies]
tokio = { version = "1.35", features = ["full"] }
axum = "0.7"
tower = "0.4"
tower-http = { version = "0.5", features = ["cors", "trace"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
thiserror = "1.0"
anyhow = "1.0"
uuid = { version = "1.6", features = ["v4", "serde"] }
dashmap = "5.5"
metrics = "0.22"
metrics-exporter-prometheus = "0.13"
futures = "0.3"
tokio-stream = "0.1"
clap = { version = "4.4", features = ["derive"] }
sqlx = { version = "0.7", features = ["runtime-tokio-rustls", "postgres", "uuid", "chrono"] }
chrono = { version = "0.4", features = ["serde"] }
*/

use axum::{
    extract::{Path, State, WebSocketUpgrade},
    http::StatusCode,
    response::{Json, Response},
    routing::{get, post},
    Router,
};
use dashmap::DashMap;
use futures::{sink::SinkExt, stream::StreamExt};
use serde::{Deserialize, Serialize};
use std::{
    collections::HashMap,
    sync::{
        atomic::{AtomicU64, Ordering},
        Arc,
    },
    time::{Duration, SystemTime, UNIX_EPOCH},
};
use tokio::{
    sync::{broadcast, mpsc, RwLock},
    time::interval,
};
use tracing::{error, info, instrument, warn};
use uuid::Uuid;

// Domain types with strong typing
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SensorReading {
    pub sensor_id: Uuid,
    pub timestamp: u64,
    pub value: f64,
    pub sensor_type: SensorType,
    pub metadata: HashMap<String, String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SensorType {
    Temperature,
    Humidity,
    Pressure,
    Motion,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProcessedReading {
    pub id: Uuid,
    pub sensor_reading: SensorReading,
    pub processed_value: f64,
    pub anomaly_score: f64,
    pub processed_at: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AggregatedMetrics {
    pub sensor_id: Uuid,
    pub window_start: u64,
    pub window_end: u64,
    pub count: u32,
    pub avg: f64,
    pub min: f64,
    pub max: f64,
    pub std_dev: f64,
}

// Error handling
#[derive(thiserror::Error, Debug)]
pub enum ProcessorError {
    #[error("Invalid sensor reading: {message}")]
    ValidationError { message: String },
    #[error("Processing failed: {source}")]
    ProcessingError { source: anyhow::Error },
    #[error("Storage error: {message}")]
    StorageError { message: String },
}

// Application state
#[derive(Clone)]
pub struct AppState {
    pub processor: Arc<DataProcessor>,
    pub metrics_store: Arc<MetricsStore>,
    pub event_broadcaster: broadcast::Sender<ProcessedReading>,
}

// Metrics storage with concurrent access
pub struct MetricsStore {
    readings: DashMap<Uuid, Vec<ProcessedReading>>,
    aggregated: DashMap<Uuid, Vec<AggregatedMetrics>>,
    processed_count: AtomicU64,
}

impl MetricsStore {
    pub fn new() -> Self {
        Self {
            readings: DashMap::new(),
            aggregated: DashMap::new(),
            processed_count: AtomicU64::new(0),
        }
    }

    pub fn store_reading(&self, reading: ProcessedReading) {
        self.readings
            .entry(reading.sensor_reading.sensor_id)
            .or_insert_with(Vec::new)
            .push(reading);
        
        self.processed_count.fetch_add(1, Ordering::Relaxed);
        
        // Keep only last 1000 readings per sensor
        if let Some(mut readings) = self.readings.get_mut(&reading.sensor_reading.sensor_id) {
            if readings.len() > 1000 {
                readings.drain(..readings.len() - 1000);
            }
        }
    }

    pub fn get_recent_readings(&self, sensor_id: &Uuid, limit: usize) -> Vec<ProcessedReading> {
        self.readings
            .get(sensor_id)
            .map(|readings| {
                readings
                    .iter()
                    .rev()
                    .take(limit)
                    .cloned()
                    .collect()
            })
            .unwrap_or_default()
    }

    pub fn get_total_processed(&self) -> u64 {
        self.processed_count.load(Ordering::Relaxed)
    }
}

// Core data processing engine
pub struct DataProcessor {
    input_rx: Arc<RwLock<Option<mpsc::Receiver<SensorReading>>>>,
    output_tx: mpsc::Sender<ProcessedReading>,
    anomaly_detector: AnomalyDetector,
}

impl DataProcessor {
    pub fn new(buffer_size: usize) -> (Self, mpsc::Sender<SensorReading>, mpsc::Receiver<ProcessedReading>) {
        let (input_tx, input_rx) = mpsc::channel(buffer_size);
        let (output_tx, output_rx) = mpsc::channel(buffer_size);

        let processor = Self {
            input_rx: Arc::new(RwLock::new(Some(input_rx))),
            output_tx,
            anomaly_detector: AnomalyDetector::new(),
        };

        (processor, input_tx, output_rx)
    }

    #[instrument(skip(self))]
    pub async fn start_processing(&self) -> Result<(), ProcessorError> {
        let mut input_rx = self.input_rx.write().await.take()
            .ok_or_else(|| ProcessorError::ProcessingError {
                source: anyhow::anyhow!("Processor already started")
            })?;

        info!("Starting data processor");

        while let Some(reading) = input_rx.recv().await {
            match self.process_reading(reading).await {
                Ok(processed) => {
                    if let Err(e) = self.output_tx.send(processed).await {
                        error!("Failed to send processed reading: {}", e);
                        break;
                    }
                }
                Err(e) => {
                    error!("Processing failed: {}", e);
                    // Continue processing other readings
                }
            }
        }

        warn!("Data processor stopped");
        Ok(())
    }

    #[instrument(skip(self))]
    async fn process_reading(&self, reading: SensorReading) -> Result<ProcessedReading, ProcessorError> {
        // Validate input
        self.validate_reading(&reading)?;

        // Apply processing algorithms
        let processed_value = self.apply_filters(reading.value).await?;
        
        // Detect anomalies
        let anomaly_score = self.anomaly_detector
            .calculate_score(&reading.sensor_id, processed_value)
            .await;

        let processed = ProcessedReading {
            id: Uuid::new_v4(),
            sensor_reading: reading,
            processed_value,
            anomaly_score,
            processed_at: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_millis() as u64,
        };

        // Update metrics
        metrics::counter!("readings_processed_total", "sensor_type" => format!("{:?}", processed.sensor_reading.sensor_type))
            .increment(1);
        
        metrics::histogram!("processing_latency_ms")
            .record((processed.processed_at - processed.sensor_reading.timestamp) as f64);

        if anomaly_score > 0.8 {
            metrics::counter!("anomalies_detected_total").increment(1);
            warn!("Anomaly detected: sensor={}, score={:.3}", 
                  processed.sensor_reading.sensor_id, anomaly_score);
        }

        Ok(processed)
    }

    fn validate_reading(&self, reading: &SensorReading) -> Result<(), ProcessorError> {
        if reading.value.is_nan() || reading.value.is_infinite() {
            return Err(ProcessorError::ValidationError {
                message: "Invalid sensor value".to_string(),
            });
        }

        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_millis() as u64;

        if reading.timestamp > now + 60_000 {  // 1 minute in future
            return Err(ProcessorError::ValidationError {
                message: "Timestamp too far in future".to_string(),
            });
        }

        Ok(())
    }

    async fn apply_filters(&self, value: f64) -> Result<f64, ProcessorError> {
        // Simulate complex async processing
        tokio::time::sleep(Duration::from_micros(100)).await;
        
        // Apply smoothing filter
        let smoothed = value * 0.8 + 0.2 * value; // Simple exponential smoothing
        
        // Apply bounds checking
        let bounded = smoothed.clamp(-1000.0, 1000.0);
        
        Ok(bounded)
    }
}

// Anomaly detection system
pub struct AnomalyDetector {
    sensor_histories: DashMap<Uuid, SensorHistory>,
}

#[derive(Debug)]
struct SensorHistory {
    values: Vec<f64>,
    mean: f64,
    variance: f64,
}

impl AnomalyDetector {
    pub fn new() -> Self {
        Self {
            sensor_histories: DashMap::new(),
        }
    }

    pub async fn calculate_score(&self, sensor_id: &Uuid, value: f64) -> f64 {
        let mut history = self.sensor_histories
            .entry(*sensor_id)
            .or_insert_with(|| SensorHistory {
                values: Vec::with_capacity(100),
                mean: value,
                variance: 0.0,
            });

        history.values.push(value);
        
        // Keep only recent history
        if history.values.len() > 100 {
            history.values.remove(0);
        }

        // Update statistics
        if history.values.len() > 1 {
            let sum: f64 = history.values.iter().sum();
            history.mean = sum / history.values.len() as f64;
            
            let variance_sum: f64 = history.values
                .iter()
                .map(|&x| (x - history.mean).powi(2))
                .sum();
            history.variance = variance_sum / history.values.len() as f64;
        }

        // Calculate anomaly score using z-score
        if history.variance > 0.0 {
            let z_score = (value - history.mean) / history.variance.sqrt();
            (z_score.abs() / 3.0).min(1.0) // Normalize to [0, 1]
        } else {
            0.0
        }
    }
}

// HTTP API handlers
#[instrument(skip(state))]
async fn submit_reading(
    State(state): State<AppState>,
    Json(reading): Json<SensorReading>,
) -> Result<Json<serde_json::Value>, StatusCode> {
    // Send to processing pipeline
    // In real implementation, you'd have access to the input sender
    info!("Received sensor reading: {:?}", reading.sensor_id);
    
    Ok(Json(serde_json::json!({
        "status": "accepted",
        "reading_id": reading.sensor_id
    })))
}

#[instrument(skip(state))]
async fn get_sensor_data(
    Path(sensor_id): Path<Uuid>,
    State(state): State<AppState>,
) -> Result<Json<Vec<ProcessedReading>>, StatusCode> {
    let readings = state.metrics_store.get_recent_readings(&sensor_id, 50);
    Ok(Json(readings))
}

#[instrument(skip(state))]
async fn get_metrics(State(state): State<AppState>) -> Json<serde_json::Value> {
    Json(serde_json::json!({
        "total_processed": state.metrics_store.get_total_processed(),
        "active_sensors": state.metrics_store.readings.len(),
        "system_health": "healthy"
    }))
}

// WebSocket handler for real-time updates
async fn websocket_handler(
    ws: WebSocketUpgrade,
    State(state): State<AppState>,
) -> Response {
    ws.on_upgrade(|socket| handle_websocket(socket, state))
}

async fn handle_websocket(socket: axum::extract::ws::WebSocket, state: AppState) {
    let (mut sender, mut receiver) = socket.split();
    let mut event_rx = state.event_broadcaster.subscribe();

    // Spawn task to handle incoming messages (if needed)
    let recv_task = tokio::spawn(async move {
        while let Some(msg) = receiver.next().await {
            if let Ok(msg) = msg {
                match msg {
                    axum::extract::ws::Message::Close(_) => break,
                    _ => {} // Handle other message types as needed
                }
            }
        }
    });

    // Send real-time updates
    let send_task = tokio::spawn(async move {
        while let Ok(processed_reading) = event_rx.recv().await {
            let message = serde_json::to_string(&processed_reading).unwrap();
            if sender
                .send(axum::extract::ws::Message::Text(message))
                .await
                .is_err()
            {
                break;
            }
        }
    });

    // Wait for either task to finish
    tokio::select! {
        _ = recv_task => {},
        _ = send_task => {},
    }
}

// Application setup
pub fn create_app(state: AppState) -> Router {
    Router::new()
        .route("/readings", post(submit_reading))
        .route("/sensors/:sensor_id/data", get(get_sensor_data))
        .route("/metrics", get(get_metrics))
        .route("/ws", get(websocket_handler))
        .with_state(state)
        .layer(
            tower::ServiceBuilder::new()
                .layer(tower_http::trace::TraceLayer::new_for_http())
                .layer(tower_http::cors::CorsLayer::permissive())
        )
}

// Main application
#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // Initialize tracing
    tracing_subscriber::fmt()
        .with_env_filter(tracing_subscriber::EnvFilter::from_default_env())
        .init();

    info!("Starting real-time data processor");

    // Create components
    let (processor, input_tx, mut output_rx) = DataProcessor::new(1000);
    let metrics_store = Arc::new(MetricsStore::new());
    let (event_tx, _) = broadcast::channel(1000);

    let app_state = AppState {
        processor: Arc::new(processor),
        metrics_store: metrics_store.clone(),
        event_broadcaster: event_tx.clone(),
    };

    // Start data processing pipeline
    let processor_handle = {
        let processor = app_state.processor.clone();
        tokio::spawn(async move {
            if let Err(e) = processor.start_processing().await {
                error!("Data processor failed: {}", e);
            }
        })
    };

    // Start output handler
    let output_handle = tokio::spawn(async move {
        while let Some(processed_reading) = output_rx.recv().await {
            // Store in metrics
            metrics_store.store_reading(processed_reading.clone());
            
            // Broadcast to WebSocket clients
            let _ = event_tx.send(processed_reading);
        }
    });

    // Start metrics reporter
    let metrics_handle = tokio::spawn(async move {
        let mut interval = interval(Duration::from_secs(30));
        loop {
            interval.tick().await;
            info!("System metrics: processed={}", 
                  metrics_store.get_total_processed());
        }
    });

    // Start HTTP server
    let app = create_app(app_state);
    let listener = tokio::net::TcpListener::bind("0.0.0.0:3000").await?;
    
    info!("Server listening on http://0.0.0.0:3000");
    
    // Graceful shutdown
    tokio::select! {
        result = axum::serve(listener, app) => {
            if let Err(e) = result {
                error!("Server error: {}", e);
            }
        }
        _ = tokio::signal::ctrl_c() => {
            info!("Shutdown signal received");
        }
        _ = processor_handle => {
            warn!("Data processor terminated");
        }
        _ = output_handle => {
            warn!("Output handler terminated");
        }
        _ = metrics_handle => {
            warn!("Metrics reporter terminated");
        }
    }

    info!("Application shutdown complete");
    Ok(())
}

// Simulation and testing utilities
#[cfg(feature = "simulation")]
pub mod simulation {
    use super::*;
    use rand::Rng;
    use tokio::time::interval;

    pub struct SensorSimulator {
        sensor_id: Uuid,
        sensor_type: SensorType,
        base_value: f64,
        noise_level: f64,
    }

    impl SensorSimulator {
        pub fn new(sensor_type: SensorType) -> Self {
            let base_value = match sensor_type {
                SensorType::Temperature => 22.0,
                SensorType::Humidity => 45.0,
                SensorType::Pressure => 1013.25,
                SensorType::Motion => 0.0,
            };

            Self {
                sensor_id: Uuid::new_v4(),
                sensor_type,
                base_value,
                noise_level: 0.1,
            }
        }

        pub async fn start_simulation(&self, tx: mpsc::Sender<SensorReading>) {
            let mut interval = interval(Duration::from_millis(100));
            let mut rng = rand::thread_rng();

            loop {
                interval.tick().await;

                let noise = rng.gen_range(-self.noise_level..=self.noise_level);
                let value = self.base_value + noise;

                let reading = SensorReading {
                    sensor_id: self.sensor_id,
                    timestamp: SystemTime::now()
                        .duration_since(UNIX_EPOCH)
                        .unwrap()
                        .as_millis() as u64,
                    value,
                    sensor_type: self.sensor_type.clone(),
                    metadata: HashMap::new(),
                };

                if tx.send(reading).await.is_err() {
                    break;
                }
            }
        }
    }

    pub async fn run_simulation(input_tx: mpsc::Sender<SensorReading>) {
        info!("Starting sensor simulation");

        let simulators = vec![
            SensorSimulator::new(SensorType::Temperature),
            SensorSimulator::new(SensorType::Humidity),
            SensorSimulator::new(SensorType::Pressure),
            SensorSimulator::new(SensorType::Motion),
        ];

        let handles: Vec<_> = simulators
            .into_iter()
            .map(|sim| {
                let tx = input_tx.clone();
                tokio::spawn(async move {
                    sim.start_simulation(tx).await;
                })
            })
            .collect();

        futures::future::join_all(handles).await;
    }
}

// Configuration management
#[derive(Debug, Clone)]
pub struct Config {
    pub server_port: u16,
    pub buffer_size: usize,
    pub max_readings_per_sensor: usize,
    pub anomaly_threshold: f64,
    pub metrics_interval_secs: u64,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            server_port: 3000,
            buffer_size: 1000,
            max_readings_per_sensor: 1000,
            anomaly_threshold: 0.8,
            metrics_interval_secs: 30,
        }
    }
}

impl Config {
    pub fn from_env() -> anyhow::Result<Self> {
        let mut config = Self::default();

        if let Ok(port) = std::env::var("SERVER_PORT") {
            config.server_port = port.parse()?;
        }

        if let Ok(buffer_size) = std::env::var("BUFFER_SIZE") {
            config.buffer_size = buffer_size.parse()?;
        }

        if let Ok(threshold) = std::env::var("ANOMALY_THRESHOLD") {
            config.anomaly_threshold = threshold.parse()?;
        }

        Ok(config)
    }
}

// Health check system
pub struct HealthChecker {
    checks: Vec<Box<dyn HealthCheck + Send + Sync>>,
}

#[async_trait::async_trait]
pub trait HealthCheck {
    async fn check(&self) -> HealthResult;
    fn name(&self) -> &'static str;
}

#[derive(Debug, Serialize)]
pub struct HealthResult {
    pub healthy: bool,
    pub message: String,
    pub details: HashMap<String, serde_json::Value>,
}

impl HealthChecker {
    pub fn new() -> Self {
        Self {
            checks: Vec::new(),
        }
    }

    pub fn add_check<T: HealthCheck + Send + Sync + 'static>(mut self, check: T) -> Self {
        self.checks.push(Box::new(check));
        self
    }

    pub async fn run_checks(&self) -> HashMap<&'static str, HealthResult> {
        let mut results = HashMap::new();
        
        for check in &self.checks {
            let result = check.check().await;
            results.insert(check.name(), result);
        }
        
        results
    }
}

// Database health check implementation
pub struct DatabaseHealthCheck {
    pool: sqlx::PgPool,
}

#[async_trait::async_trait]
impl HealthCheck for DatabaseHealthCheck {
    async fn check(&self) -> HealthResult {
        match sqlx::query("SELECT 1").fetch_one(&self.pool).await {
            Ok(_) => HealthResult {
                healthy: true,
                message: "Database connection healthy".to_string(),
                details: HashMap::new(),
            },
            Err(e) => HealthResult {
                healthy: false,
                message: format!("Database connection failed: {}", e),
                details: HashMap::new(),
            },
        }
    }

    fn name(&self) -> &'static str {
        "database"
    }
}

// Memory usage health check
pub struct MemoryHealthCheck;

#[async_trait::async_trait]
impl HealthCheck for MemoryHealthCheck {
    async fn check(&self) -> HealthResult {
        // In a real implementation, you'd use a system info crate
        let mut details = HashMap::new();
        details.insert("memory_usage".to_string(), serde_json::Value::String("OK".to_string()));
        
        HealthResult {
            healthy: true,
            message: "Memory usage within limits".to_string(),
            details,
        }
    }

    fn name(&self) -> &'static str {
        "memory"
    }
}

// Advanced metrics collection
pub struct MetricsCollector {
    registry: prometheus::Registry,
}

impl MetricsCollector {
    pub fn new() -> anyhow::Result<Self> {
        let registry = prometheus::Registry::new();
        
        // Register custom metrics
        let readings_counter = prometheus::CounterVec::new(
            prometheus::Opts::new("readings_total", "Total number of readings processed"),
            &["sensor_type", "status"]
        )?;
        
        let processing_duration = prometheus::HistogramVec::new(
            prometheus::HistogramOpts::new("processing_duration_seconds", "Processing duration in seconds"),
            &["operation"]
        )?;
        
        registry.register(Box::new(readings_counter))?;
        registry.register(Box::new(processing_duration))?;
        
        Ok(Self { registry })
    }
    
    pub fn get_metrics(&self) -> String {
        use prometheus::Encoder;
        let encoder = prometheus::TextEncoder::new();
        let metric_families = self.registry.gather();
        encoder.encode_to_string(&metric_families).unwrap_or_default()
    }
}

// Command-line interface
use clap::{Parser, Subcommand};

#[derive(Parser)]
#[command(name = "realtime-processor")]
#[command(about = "A high-performance real-time data processing system")]
struct Cli {
    #[command(subcommand)]
    command: Commands,
    
    #[arg(short, long, action = clap::ArgAction::Count)]
    verbose: u8,
}

#[derive(Subcommand)]
enum Commands {
    /// Start the server
    Serve {
        #[arg(short, long, default_value = "3000")]
        port: u16,
        
        #[arg(long)]
        simulate: bool,
    },
    /// Check system health
    Health,
    /// Show metrics
    Metrics,
}

// Enhanced main function with CLI
pub async fn run_cli() -> anyhow::Result<()> {
    let cli = Cli::parse();
    
    // Initialize logging based on verbosity
    let log_level = match cli.verbose {
        0 => "info",
        1 => "debug",
        _ => "trace",
    };
    
    tracing_subscriber::fmt()
        .with_env_filter(
            tracing_subscriber::EnvFilter::try_from_default_env()
                .unwrap_or_else(|_| tracing_subscriber::EnvFilter::new(log_level))
        )
        .init();

    match cli.command {
        Commands::Serve { port, simulate } => {
            run_server(port, simulate).await
        }
        Commands::Health => {
            run_health_check().await
        }
        Commands::Metrics => {
            show_metrics().await
        }
    }
}

async fn run_server(port: u16, simulate: bool) -> anyhow::Result<()> {
    info!("Starting server on port {}", port);
    
    let config = Config::from_env()?;
    let (processor, input_tx, mut output_rx) = DataProcessor::new(config.buffer_size);
    let metrics_store = Arc::new(MetricsStore::new());
    let (event_tx, _) = broadcast::channel(1000);

    let app_state = AppState {
        processor: Arc::new(processor),
        metrics_store: metrics_store.clone(),
        event_broadcaster: event_tx.clone(),
    };

    // Start simulation if requested
    if simulate {
        let sim_tx = input_tx.clone();
        tokio::spawn(async move {
            #[cfg(feature = "simulation")]
            simulation::run_simulation(sim_tx).await;
        });
    }

    // Continue with server startup as before...
    let app = create_app(app_state);
    let listener = tokio::net::TcpListener::bind(format!("0.0.0.0:{}", port)).await?;
    
    info!("Server ready at http://0.0.0.0:{}", port);
    axum::serve(listener, app).await?;
    
    Ok(())
}

async fn run_health_check() -> anyhow::Result<()> {
    let health_checker = HealthChecker::new()
        .add_check(MemoryHealthCheck);
    
    let results = health_checker.run_checks().await;
    
    for (name, result) in results {
        let status = if result.healthy { "✅" } else { "❌" };
        println!("{} {}: {}", status, name, result.message);
    }
    
    Ok(())
}

async fn show_metrics() -> anyhow::Result<()> {
    let collector = MetricsCollector::new()?;
    println!("{}", collector.get_metrics());
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::timeout;

    #[tokio::test]
    async fn test_data_processor() {
        let (processor, input_tx, mut output_rx) = DataProcessor::new(10);
        
        // Start processor
        let processor_handle = tokio::spawn(async move {
            processor.start_processing().await.unwrap();
        });
        
        // Send test reading
        let reading = SensorReading {
            sensor_id: Uuid::new_v4(),
            timestamp: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_millis() as u64,
            value: 25.0,
            sensor_type: SensorType::Temperature,
            metadata: HashMap::new(),
        };
        
        input_tx.send(reading.clone()).await.unwrap();
        drop(input_tx); // Close input to stop processor
        
        // Receive processed reading
        let processed = timeout(Duration::from_secs(1), output_rx.recv())
            .await
            .unwrap()
            .unwrap();
        
        assert_eq!(processed.sensor_reading.sensor_id, reading.sensor_id);
        assert!(processed.anomaly_score >= 0.0 && processed.anomaly_score <= 1.0);
        
        processor_handle.await.unwrap();
    }

    #[tokio::test]
    async fn test_metrics_store() {
        let store = MetricsStore::new();
        let sensor_id = Uuid::new_v4();
        
        let reading = ProcessedReading {
            id: Uuid::new_v4(),
            sensor_reading: SensorReading {
                sensor_id,
                timestamp: 12345,
                value: 20.0,
                sensor_type: SensorType::Temperature,
                metadata: HashMap::new(),
            },
            processed_value: 20.0,
            anomaly_score: 0.1,
            processed_at: 12346,
        };
        
        store.store_reading(reading.clone());
        
        let retrieved = store.get_recent_readings(&sensor_id, 10);
        assert_eq!(retrieved.len(), 1);
        assert_eq!(retrieved[0].id, reading.id);
        assert_eq!(store.get_total_processed(), 1);
    }

    #[tokio::test]
    async fn test_anomaly_detector() {
        let detector = AnomalyDetector::new();
        let sensor_id = Uuid::new_v4();
        
        // Normal values should have low anomaly scores
        let score1 = detector.calculate_score(&sensor_id, 20.0).await;
        let score2 = detector.calculate_score(&sensor_id, 21.0).await;
        let score3 = detector.calculate_score(&sensor_id, 19.0).await;
        
        assert!(score1 >= 0.0 && score1 <= 1.0);
        assert!(score2 >= 0.0 && score2 <= 1.0);
        assert!(score3 >= 0.0 && score3 <= 1.0);
        
        // Outlier should have higher anomaly score
        let outlier_score = detector.calculate_score(&sensor_id, 100.0).await;
        assert!(outlier_score > score1);
        assert!(outlier_score > score2);
        assert!(outlier_score > score3);
    }
}
```
